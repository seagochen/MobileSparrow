{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac2ddc9e",
   "metadata": {},
   "source": [
    "# SSDLite_FPN 训练笔记"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899aa05f",
   "metadata": {},
   "source": [
    "## 安装依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f96b1174",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install torchvision\n",
    "!pip -q install tqdm\n",
    "!pip -q install timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de39a437",
   "metadata": {},
   "source": [
    "## 导入工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18bb3c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入系统库\n",
    "import os\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 导入sparrow\n",
    "from sparrow.models.ssdlite_fpn import SSDLite_FPN\n",
    "from sparrow.datasets.coco_dets import create_dets_dataloader\n",
    "from sparrow.losses.ssdlite_loss import SSDLoss, AnchorGenerator\n",
    "from sparrow.utils.torch_utils import EMA, evaluate, visualize_predictions\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "# 导入torch库\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69cc0dd",
   "metadata": {},
   "source": [
    "## 参数设置\n",
    "\n",
    "### 系统参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adcf6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "INPUT_SIZE = 320\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 4\n",
    "NUM_CLASSES = 80 # COCO 数据集定义数\n",
    "ANCHOR_SIZES = [32, 64, 128, 256, 512]\n",
    "ANCHOR_RATIOS = [0.5, 1.0, 2.0, 1/3.0, 3.0]\n",
    "\n",
    "WEIGHTS_DIR = \"./outputs/ssdlite\" # 保存权重的目录\n",
    "TEST_IMAGE_PATH = \"./res/india_road.png\" # 你的测试图片路径"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c034db9c",
   "metadata": {},
   "source": [
    "### 学习参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60f45e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_EPOCH = 0\n",
    "LOG_INTERVAL_SAMPLES = 1000\n",
    "EPOCHS=100\n",
    "log_interval_batches = max(1, LOG_INTERVAL_SAMPLES // BATCH_SIZE)\n",
    "BEST_VAL_LOSS = float('inf')\n",
    "LEARNING_RATE = 1e-4 # 初始学习率\n",
    "WEIGHT_DECAY = 1e-3\n",
    "WARMUP_EPOCHS = 2 # <--- 新增：预热的 epoch 数量\n",
    "GRADIENT_CLIP_VAL = 5.0 # <--- 新增：梯度裁剪的阈值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cae9896",
   "metadata": {},
   "source": [
    "## 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8da76bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    }
   ],
   "source": [
    "backbone_fpn = timm.create_model('mobilenetv3_large_100', pretrained=True, features_only=True, out_indices=(2, 3, 4))\n",
    "model_fpn = SSDLite_FPN(backbone_fpn, num_classes=NUM_CLASSES, fpn_out_channels=128, num_anchors=len(ANCHOR_RATIOS))\n",
    "model_fpn.to(device)\n",
    "\n",
    "# EMA评估器\n",
    "ema = EMA(model_fpn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5054edf0",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38f7ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_ROOT = \"/home/cxt/projects/MobileSparrow/data/coco2017\"\n",
    "\n",
    "# 数据加载器 (来自 dataloader.py)\n",
    "train_aug_config = { \"rotate_deg\": 15.0, \"min_box_size\": 2.0 }\n",
    "train_loader = create_dets_dataloader(\n",
    "    dataset_root=COCO_ROOT,\n",
    "    img_size=INPUT_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    "    aug_cfg=train_aug_config,\n",
    "    is_train=True\n",
    ")\n",
    "\n",
    "# --- 新增：创建验证集数据加载器 ---\n",
    "val_aug_config = { \"min_box_size\": 2.0 } # 验证集通常不做复杂增强\n",
    "val_loader = create_dets_dataloader(\n",
    "    dataset_root=COCO_ROOT,\n",
    "    img_size=INPUT_SIZE,\n",
    "    batch_size=BATCH_SIZE * 2,  # 验证时通常可以用更大的 batch size\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    "    aug_cfg=val_aug_config,\n",
    "    is_train=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b6535f",
   "metadata": {},
   "source": [
    "## 损失优化调度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fbfa59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "criterion = SSDLoss(num_classes=NUM_CLASSES)\n",
    "\n",
    "# 优化器\n",
    "optimizer = torch.optim.AdamW(model_fpn.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# 学习调度器\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc13295",
   "metadata": {},
   "source": [
    "## 加载预训练权重\n",
    "\n",
    "确保每次训练不必从头再来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0086d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resuming training from last.pt ---\n",
      "Resumed from epoch 52. Best validation loss so far: 20.3773\n",
      "Current learning rate is 0.000047\n"
     ]
    }
   ],
   "source": [
    "# 确保存放预训练的目录存在\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True) # 确保目录存在\n",
    "\n",
    "# 断点续训逻辑\n",
    "last_pt_path = os.path.join(WEIGHTS_DIR, \"last.pt\")\n",
    "if os.path.exists(last_pt_path):\n",
    "    print(\"--- Resuming training from last.pt ---\")\n",
    "\n",
    "    # 加载pt文件\n",
    "    checkpoint = torch.load(last_pt_path, map_location=device)\n",
    "    \n",
    "    # 从pt中读取模型权重\n",
    "    model_fpn.load_state_dict(checkpoint['model'])\n",
    "    \n",
    "    # 加载EMA状态\n",
    "    ema.ema_model.load_state_dict(checkpoint['ema_model'])\n",
    "\n",
    "    # 加载优化器状态\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "    # 加载调度器状态\n",
    "    scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "\n",
    "    # 更新EPOCH状态\n",
    "    START_EPOCH = checkpoint['epoch'] + 1\n",
    "    \n",
    "    # 更新最佳损失状态\n",
    "    BEST_VAL_LOSS = checkpoint['best_val_loss']\n",
    "    \n",
    "    # 打印确认消息\n",
    "    print(f\"Resumed from epoch {START_EPOCH-1}. Best validation loss so far: {BEST_VAL_LOSS:.4f}\")\n",
    "    print(f\"Current learning rate is {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36111e8a",
   "metadata": {},
   "source": [
    "## 预处理 anchor boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e92c45f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computing anchors for fixed input size...\n",
      "Anchors pre-computed. Shape: torch.Size([10670, 4])\n"
     ]
    }
   ],
   "source": [
    "# --- 预计算锚框 (核心步骤) ---\n",
    "print(\"Pre-computing anchors for fixed input size...\")\n",
    "anchor_generator = AnchorGenerator(\n",
    "    sizes=ANCHOR_SIZES,\n",
    "    aspect_ratios=ANCHOR_RATIOS\n",
    ")\n",
    "\n",
    "# 创建一个虚拟输入\n",
    "dummy_input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE).to(device)\n",
    "\n",
    "# 设置为 eval 模式，并确保没有梯度计算\n",
    "model_fpn.eval()\n",
    "with torch.no_grad():\n",
    "    # 手动执行一次特征提取流程，以获取特征图尺寸\n",
    "    features = model_fpn.backbone(dummy_input)\n",
    "    p3, p4, p5 = model_fpn.fpn(features)\n",
    "    p6 = model_fpn.extra_layers[0](p5)\n",
    "    p7 = model_fpn.extra_layers[1](p6)\n",
    "    feature_maps_for_size_calc = [p3, p4, p5, p6, p7]\n",
    "\n",
    "# 使用获取的特征图列表生成一次性的、完整的锚框网格\n",
    "# 这个 precomputed_anchors 将在整个训练过程中被重复使用\n",
    "precomputed_anchors = anchor_generator.generate_anchors_on_grid(feature_maps_for_size_calc, device)\n",
    "print(f\"Anchors pre-computed. Shape: {precomputed_anchors.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f57db9",
   "metadata": {},
   "source": [
    "## 启动训练循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f16739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Training ---\n",
      "Logging average loss every 125 batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100 [Training]:  73%|███████▎  | 10753/14785 [05:11<01:58, 33.93it/s, cls=0.3789, reg=0.0716]"
     ]
    }
   ],
   "source": [
    "# --- 训练循环 ---\n",
    "print(\"\\n--- Starting Training ---\")\n",
    "model_fpn.train() # 切换回训练模式\n",
    "print(f\"Logging average loss every {log_interval_batches} batches.\")  # 日志的打印频率 \n",
    "\n",
    "# 计算预热的总步数\n",
    "warmup_steps = WARMUP_EPOCHS * len(train_loader)\n",
    "current_step = START_EPOCH * len(train_loader)\n",
    "\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "    model_fpn.train() # 设置为训练模式\n",
    "    \n",
    "    epoch_loss_cls = 0.0\n",
    "    epoch_loss_reg = 0.0\n",
    "\n",
    "    # 进度条信息    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Training]\")\n",
    "    \n",
    "    for i, (imgs, targets, _) in enumerate(pbar):\n",
    "        # --- 学习率预热逻辑 ---\n",
    "        if current_step < warmup_steps:\n",
    "            # 线性预热\n",
    "            lr_scale = (current_step + 1) / warmup_steps\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = LEARNING_RATE * lr_scale\n",
    "\n",
    "        # --- 正常训练步骤 ---\n",
    "        imgs = imgs.to(device)\n",
    "        targets_on_device = [t.to(device) for t in targets]\n",
    "        cls_preds, reg_preds = model_fpn(imgs)\n",
    "        loss_cls, loss_reg = criterion(precomputed_anchors, cls_preds, reg_preds, targets_on_device)\n",
    "        total_loss = loss_cls + loss_reg\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "\n",
    "        # --- 新增：梯度裁剪 ---\n",
    "        torch.nn.utils.clip_grad_norm_(model_fpn.parameters(), max_norm=GRADIENT_CLIP_VAL)\n",
    "        \n",
    "        # 微调模型参数\n",
    "        optimizer.step()\n",
    "\n",
    "        # --- 更新 EMA ---\n",
    "        # 更新 EMA 和步数计数器\n",
    "        ema.update(model_fpn)\n",
    "        current_step += 1\n",
    "        \n",
    "        epoch_loss_cls += loss_cls.item()\n",
    "        epoch_loss_reg += loss_reg.item()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        pbar.set_postfix(cls=f\"{loss_cls.item():.4f}\", reg=f\"{loss_reg.item():.4f}\")\n",
    "\n",
    "    # 每个 epoch 结束后，更新学习率调度器\n",
    "    if epoch >= WARMUP_EPOCHS - 1: # -1 是因为 step() 应在 optimizer.step() 之后调用\n",
    "        scheduler.step()\n",
    "\n",
    "    # 每个 epoch 结束后，进行验证\n",
    "    avg_val_loss, _, _ = evaluate(ema.ema_model, val_loader, criterion, anchor_generator, precomputed_anchors, device)\n",
    "    print(f\"\\n---> Epoch {epoch+1}/{EPOCHS} Validation Summary <---\")\n",
    "    print(f\"  Average Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # --- 保存 last.pt 和 best.pt ---\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model': model_fpn.state_dict(),\n",
    "        'ema_model': ema.ema_model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'scheduler': scheduler.state_dict(), # <--- 保存 scheduler 状态\n",
    "        'best_val_loss': BEST_VAL_LOSS,\n",
    "    }\n",
    "    \n",
    "    # 保存 last.pt\n",
    "    torch.save(checkpoint, last_pt_path)\n",
    "    print(f\"  Saved last checkpoint to {last_pt_path}\")\n",
    "    \n",
    "    # 如果当前是最佳模型，则保存 best.pt\n",
    "    if avg_val_loss < BEST_VAL_LOSS:\n",
    "        BEST_VAL_LOSS = avg_val_loss\n",
    "        checkpoint['best_val_loss'] = BEST_VAL_LOSS # 更新 checkpoint 中的最佳损失\n",
    "        best_pt_path = os.path.join(WEIGHTS_DIR, \"best.pt\")\n",
    "        torch.save(checkpoint, best_pt_path)\n",
    "        print(f\"  >>> New best model found! Saved to {best_pt_path}\\n\")\n",
    "    \n",
    "    # --- 每 10 个 epoch，可视化一次预测结果 ---\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"\\n--- Visualizing predictions at epoch {epoch+1} ---\")\n",
    "        viz_dir = os.path.join(WEIGHTS_DIR, \"viz\")\n",
    "        os.makedirs(viz_dir, exist_ok=True)\n",
    "        save_path = os.path.join(viz_dir, f\"epoch_{epoch+1:03d}.png\")\n",
    "        visualize_predictions(\n",
    "            model=ema.ema_model,\n",
    "            image_path=TEST_IMAGE_PATH,\n",
    "            anchor_generator=anchor_generator,\n",
    "            device=device,\n",
    "            precomputed_anchors=precomputed_anchors,\n",
    "            conf_thresh=0.3,\n",
    "            nms_thresh=0.45,\n",
    "            save_path=save_path,   # 保存，不show\n",
    "            show=False\n",
    "        )\n",
    "\n",
    "print(\"--- Training Finished ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272654c0",
   "metadata": {},
   "source": [
    "使用这些技巧后为什么误差不再剧烈抖动：\n",
    "\n",
    "1.  **Warm-up**：在最初的 `WARMUP_EPOCHS` 个周期里，学习率会从一个接近0的值慢慢爬升到 `1e-4`。这给了模型充足的时间来适应数据，预测头的权重会从随机状态平稳地过渡到一个更有意义的状态，避免了初期的梯度爆炸。\n",
    "2.  **Gradient Clipping**：即使在预热后，偶尔也可能遇到特别困难的样本导致梯度激增。`clip_grad_norm_` 就像一个保险丝，能确保任何一次的更新都不会过大，从而保证了训练过程的平滑。\n",
    "3.  **CosineAnnealingLR**：在模型度过初期、趋于稳定后，这个调度器会开始工作，它会像余弦曲线一样，缓慢地将学习率从 `1e-4` 降低到一个非常小的值（`1e-6`）。这使得模型在训练后期能够在损失的“山谷”底部进行精细搜索，从而找到一个更好的局部最优解。\n",
    "\n",
    "**建议**：\n",
    "请使用这个新的训练脚本来重新开始训练（可以先删除旧的 `outputs` 目录）。你将会观察到，验证集损失的下降过程会变得**平滑得多**，不会再出现几百上千的剧烈跳动，模型的收敛会更稳定、效果也更有可能达到最佳。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparrow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
