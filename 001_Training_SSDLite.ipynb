{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac2ddc9e",
   "metadata": {},
   "source": [
    "# SSDLite_FPN è®­ç»ƒç¬”è®°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899aa05f",
   "metadata": {},
   "source": [
    "## å®‰è£…ä¾èµ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f96b1174",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install torchvision\n",
    "!pip -q install tqdm\n",
    "!pip -q install timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de39a437",
   "metadata": {},
   "source": [
    "## å¯¼å…¥å·¥ç¨‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18bb3c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cxt/miniconda3/envs/sparrow/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥ç³»ç»Ÿåº“\n",
    "import os\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# å¯¼å…¥sparrow\n",
    "from sparrow.models.ssdlite_fpn import SSDLite_FPN\n",
    "from sparrow.datasets.coco_dets import create_dets_dataloader\n",
    "from sparrow.losses.ssdlite_loss import SSDLoss, AnchorGenerator, evaluate\n",
    "from sparrow.utils.ema import EMA\n",
    "from sparrow.utils.visual_ssdlite import visualize_ssdlite, update_classes\n",
    "\n",
    "# å¯¼å…¥torchåº“\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69cc0dd",
   "metadata": {},
   "source": [
    "## å‚æ•°è®¾ç½®\n",
    "\n",
    "### ç³»ç»Ÿå‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcf6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "INPUT_SIZE = 320\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# ./data/coco2017_ssdlite åªåŒ…å«äº† person,backpack,handbag,suitcase\n",
    "NUM_CLASSES = 4 \n",
    "\n",
    "# æ›´æ–°æ ‡ç­¾\n",
    "update_classes(['person', 'backpack', 'handbag', 'suitcase'])\n",
    "\n",
    "# å°ºåº¦ï¼ˆæ¯å±‚ 1 ä¸ªï¼‰ï¼šå°ç›®æ ‡æ›´å‹å¥½\n",
    "ANCHOR_SIZES  = [16, 32, 64, 128, 224]   # å¯¹åº” P3..P7\n",
    "\n",
    "# æ¯”ä¾‹ï¼ˆw/hï¼‰ï¼šåâ€œç«–ç›´+ç•¥æ¨ªå‘â€ï¼Œè¦†ç›–äºº&ç®±åŒ…\n",
    "ANCHOR_RATIOS = [0.40, 0.60, 0.85, 1.20, 1.60]\n",
    "\n",
    "# COCOè®­ç»ƒæ•°æ®é›†ï¼ˆå·²ç­›é€‰ï¼Œç›®å‰åªæœ‰person,backpack,handbag,suitcase)\n",
    "COCO_ROOT = \"./data/coco2017_ssdlite\"\n",
    "\n",
    "# ä¿å­˜æƒé‡çš„ç›®å½•\n",
    "WEIGHTS_DIR = \"./outputs/ssdlite\"\n",
    "\n",
    "# æµ‹è¯•å›¾ç‰‡åœ°å€\n",
    "TEST_IMAGE_PATH = \"./res/camera1.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c034db9c",
   "metadata": {},
   "source": [
    "### å­¦ä¹ å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60f45e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_EPOCH = 0\n",
    "EPOCHS=100                      # è®­ç»ƒæ¬¡æ•°\n",
    "BEST_VAL_LOSS = float('inf')\n",
    "LEARNING_RATE = 1e-4            # åˆå§‹å­¦ä¹ ç‡\n",
    "WEIGHT_DECAY = 1e-3\n",
    "WARMUP_EPOCHS = 2               # é¢„çƒ­\n",
    "GRADIENT_CLIP_VAL = 5.0         # æ¢¯åº¦è£å‰ªçš„é˜ˆå€¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cae9896",
   "metadata": {},
   "source": [
    "## åˆ›å»ºæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8da76bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    }
   ],
   "source": [
    "backbone_fpn = timm.create_model('mobilenetv3_large_100', pretrained=True, features_only=True, out_indices=(2, 3, 4))\n",
    "model_fpn = SSDLite_FPN(backbone_fpn, num_classes=NUM_CLASSES, fpn_out_channels=128, num_anchors=len(ANCHOR_RATIOS))\n",
    "model_fpn.to(device)\n",
    "\n",
    "# EMAè¯„ä¼°å™¨\n",
    "ema = EMA(model_fpn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5054edf0",
   "metadata": {},
   "source": [
    "## åŠ è½½æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38f7ee36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cxt/projects/MobileSparrow/sparrow/datasets/coco_dets.py:182: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  transforms.append(A.PadIfNeeded(\n",
      "/home/cxt/miniconda3/envs/sparrow/lib/python3.10/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/home/cxt/projects/MobileSparrow/sparrow/datasets/coco_dets.py:194: UserWarning: Argument(s) 'value' are not valid for transform ShiftScaleRotate\n",
      "  transforms.append(A.ShiftScaleRotate(\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨ (æ¥è‡ª dataloader.py)\n",
    "train_aug_config = { \"rotate_deg\": 15.0, \"min_box_size\": 2.0 }\n",
    "train_loader = create_dets_dataloader(\n",
    "    dataset_root=COCO_ROOT,\n",
    "    img_size=INPUT_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    "    aug_cfg=train_aug_config,\n",
    "    is_train=True\n",
    ")\n",
    "\n",
    "# åˆ›å»ºéªŒè¯é›†æ•°æ®åŠ è½½å™¨\n",
    "val_aug_config = { \"min_box_size\": 2.0 } # éªŒè¯é›†é€šå¸¸ä¸åšå¤æ‚å¢å¼º\n",
    "val_loader = create_dets_dataloader(\n",
    "    dataset_root=COCO_ROOT,\n",
    "    img_size=INPUT_SIZE,\n",
    "    batch_size=BATCH_SIZE * 2,  # éªŒè¯æ—¶é€šå¸¸å¯ä»¥ç”¨æ›´å¤§çš„ batch size\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    "    aug_cfg=val_aug_config,\n",
    "    is_train=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b6535f",
   "metadata": {},
   "source": [
    "## æŸå¤±ä¼˜åŒ–è°ƒåº¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fbfa59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸå¤±å‡½æ•°\n",
    "criterion = SSDLoss(num_classes=NUM_CLASSES, iou_threshold_pos=0.45, iou_threshold_neg=0.40)\n",
    "\n",
    "# ä¼˜åŒ–å™¨\n",
    "optimizer = torch.optim.AdamW(model_fpn.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# å­¦ä¹ è°ƒåº¦å™¨\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc13295",
   "metadata": {},
   "source": [
    "## åŠ è½½é¢„è®­ç»ƒæƒé‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0086d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resuming training from last.pt ---\n",
      "Resumed from epoch 37. Best validation loss so far: 0.0103\n",
      "Current learning rate is 0.000070\n"
     ]
    }
   ],
   "source": [
    "# ç¡®ä¿å­˜æ”¾é¢„è®­ç»ƒçš„ç›®å½•å­˜åœ¨\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True) # ç¡®ä¿ç›®å½•å­˜åœ¨\n",
    "\n",
    "# æ–­ç‚¹ç»­è®­é€»è¾‘\n",
    "last_pt_path = os.path.join(WEIGHTS_DIR, \"last.pt\")\n",
    "if os.path.exists(last_pt_path):\n",
    "    print(\"--- Resuming training from last.pt ---\")\n",
    "\n",
    "    # åŠ è½½ptæ–‡ä»¶\n",
    "    checkpoint = torch.load(last_pt_path, map_location=device)\n",
    "    \n",
    "    # ä»ptä¸­è¯»å–æ¨¡å‹æƒé‡\n",
    "    model_fpn.load_state_dict(checkpoint['model'])\n",
    "    \n",
    "    # åŠ è½½EMAçŠ¶æ€\n",
    "    ema.ema_model.load_state_dict(checkpoint['ema_model'])\n",
    "\n",
    "    # åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "    # åŠ è½½è°ƒåº¦å™¨çŠ¶æ€\n",
    "    scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "\n",
    "    # æ›´æ–°EPOCHçŠ¶æ€\n",
    "    START_EPOCH = checkpoint['epoch'] + 1\n",
    "    \n",
    "    # æ›´æ–°æœ€ä½³æŸå¤±çŠ¶æ€\n",
    "    BEST_VAL_LOSS = checkpoint['best_val_loss']\n",
    "    \n",
    "    # æ‰“å°ç¡®è®¤æ¶ˆæ¯\n",
    "    print(f\"Resumed from epoch {START_EPOCH-1}. Best validation loss so far: {BEST_VAL_LOSS:.4f}\")\n",
    "    print(f\"Current learning rate is {optimizer.param_groups[0]['lr']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36111e8a",
   "metadata": {},
   "source": [
    "## é¢„å¤„ç† anchor boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e92c45f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-computing anchors for fixed input size...\n",
      "Anchors pre-computed. Shape: torch.Size([10670, 4])\n"
     ]
    }
   ],
   "source": [
    "# --- é¢„è®¡ç®—é”šæ¡† (æ ¸å¿ƒæ­¥éª¤) ---\n",
    "print(\"Pre-computing anchors for fixed input size...\")\n",
    "anchor_generator = AnchorGenerator(\n",
    "    sizes=ANCHOR_SIZES,\n",
    "    aspect_ratios=ANCHOR_RATIOS\n",
    ")\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿè¾“å…¥\n",
    "dummy_input = torch.randn(1, 3, INPUT_SIZE, INPUT_SIZE).to(device)\n",
    "\n",
    "# è®¾ç½®ä¸º eval æ¨¡å¼ï¼Œå¹¶ç¡®ä¿æ²¡æœ‰æ¢¯åº¦è®¡ç®—\n",
    "model_fpn.eval()\n",
    "with torch.no_grad():\n",
    "    # æ‰‹åŠ¨æ‰§è¡Œä¸€æ¬¡ç‰¹å¾æå–æµç¨‹ï¼Œä»¥è·å–ç‰¹å¾å›¾å°ºå¯¸\n",
    "    features = model_fpn.backbone(dummy_input)\n",
    "    p3, p4, p5 = model_fpn.fpn(features)\n",
    "    p6 = model_fpn.extra_layers[0](p5)\n",
    "    p7 = model_fpn.extra_layers[1](p6)\n",
    "    feature_maps_for_size_calc = [p3, p4, p5, p6, p7]\n",
    "\n",
    "# ä½¿ç”¨è·å–çš„ç‰¹å¾å›¾åˆ—è¡¨ç”Ÿæˆä¸€æ¬¡æ€§çš„ã€å®Œæ•´çš„é”šæ¡†ç½‘æ ¼\n",
    "# è¿™ä¸ª precomputed_anchors å°†åœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­è¢«é‡å¤ä½¿ç”¨\n",
    "precomputed_anchors = anchor_generator.generate_anchors_on_grid(feature_maps_for_size_calc, device)\n",
    "print(f\"Anchors pre-computed. Shape: {precomputed_anchors.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f57db9",
   "metadata": {},
   "source": [
    "## è®­ç»ƒå¾ªç¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f16739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Training ---\n",
      "\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000070 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:46<00:00, 36.32it/s, cls=0.967863, reg=166.828935]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 57.27it/s, cls=0.018854, reg=1.762884]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 39/100 average loss: 0.0104\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000069 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:47<00:00, 36.04it/s, cls=0.962278, reg=167.059467]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 59.80it/s, cls=0.018840, reg=1.765562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 40/100 average loss: 0.0104\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ“Š Visualized predictions on test images\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_040_001_bags.png\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_040_002_camera1.png\n",
      "\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000067 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:48<00:00, 35.95it/s, cls=0.959341, reg=165.248447]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 65.52it/s, cls=0.018794, reg=1.760963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 41/100 average loss: 0.0104\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000066 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:48<00:00, 35.90it/s, cls=0.960658, reg=164.926190]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 60.59it/s, cls=0.018853, reg=1.762838]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 42/100 average loss: 0.0104\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000064 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:49<00:00, 35.81it/s, cls=0.959480, reg=164.491630]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 60.11it/s, cls=0.018794, reg=1.753162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 43/100 average loss: 0.0104\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000063 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:48<00:00, 35.89it/s, cls=0.954498, reg=163.367310]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 60.19it/s, cls=0.018915, reg=1.751325]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 44/100 average loss: 0.0104\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000061 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:48<00:00, 35.95it/s, cls=0.949968, reg=163.638826]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 63.38it/s, cls=0.018633, reg=1.743363]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 45/100 average loss: 0.0103\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "  ğŸ“Š Visualized predictions on test images\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_045_001_bags.png\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_045_002_camera1.png\n",
      "\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000060 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:49<00:00, 35.73it/s, cls=0.948669, reg=163.391846]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 64.04it/s, cls=0.018635, reg=1.741933]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 46/100 average loss: 0.0103\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000058 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:49<00:00, 35.74it/s, cls=0.948126, reg=163.346059]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 60.86it/s, cls=0.018616, reg=1.742706]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 47/100 average loss: 0.0103\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000057 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:51<00:00, 35.52it/s, cls=0.947674, reg=162.236570]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 63.28it/s, cls=0.018727, reg=1.743348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 48/100 average loss: 0.0103\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000055 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:50<00:00, 35.61it/s, cls=0.945966, reg=162.011808]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 63.74it/s, cls=0.018566, reg=1.731290]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 49/100 average loss: 0.0102\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000054 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:50<00:00, 35.60it/s, cls=0.944049, reg=161.836844]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 57.59it/s, cls=0.018584, reg=1.729780]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 50/100 average loss: 0.0102\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "  ğŸ“Š Visualized predictions on test images\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_050_001_bags.png\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_050_002_camera1.png\n",
      "\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000052 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:50<00:00, 35.65it/s, cls=0.942701, reg=161.783440]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 65.14it/s, cls=0.018487, reg=1.727669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 51/100 average loss: 0.0102\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000051 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:51<00:00, 35.46it/s, cls=0.939170, reg=161.462265]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 63.85it/s, cls=0.018455, reg=1.724331]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 52/100 average loss: 0.0102\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000049 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:49<00:00, 35.76it/s, cls=0.942297, reg=160.228453]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 61.31it/s, cls=0.018536, reg=1.721487]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 53/100 average loss: 0.0102\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000047 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:50<00:00, 35.66it/s, cls=0.936551, reg=160.153579]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 62.35it/s, cls=0.018438, reg=1.716719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 54/100 average loss: 0.0101\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000046 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:50<00:00, 35.71it/s, cls=0.936943, reg=159.946009]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 61.29it/s, cls=0.018409, reg=1.712341]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 55/100 average loss: 0.0101\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "  ğŸ“Š Visualized predictions on test images\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_055_001_bags.png\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_055_002_camera1.png\n",
      "\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000044 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:49<00:00, 35.74it/s, cls=0.934587, reg=159.615716]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 61.69it/s, cls=0.018317, reg=1.709464]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 56/100 average loss: 0.0101\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000043 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:50<00:00, 35.64it/s, cls=0.931387, reg=158.822819]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:03<00:00, 56.23it/s, cls=0.018289, reg=1.708018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 57/100 average loss: 0.0101\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000041 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:51<00:00, 35.44it/s, cls=0.930668, reg=158.445981]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 59.29it/s, cls=0.018349, reg=1.707890]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 58/100 average loss: 0.0101\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000040 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:51<00:00, 35.48it/s, cls=0.928885, reg=158.032164]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 63.93it/s, cls=0.018294, reg=1.707101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 59/100 average loss: 0.0101\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000038 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:51<00:00, 35.48it/s, cls=0.928706, reg=157.087487]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 63.11it/s, cls=0.018284, reg=1.705340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 60/100 average loss: 0.0101\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "  ğŸ“Š Visualized predictions on test images\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_060_001_bags.png\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_060_002_camera1.png\n",
      "\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000037 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:51<00:00, 35.53it/s, cls=0.927189, reg=157.314979]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 57.02it/s, cls=0.018246, reg=1.703201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 61/100 average loss: 0.0101\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000035 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:52<00:00, 35.40it/s, cls=0.929639, reg=157.093317]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 64.70it/s, cls=0.018255, reg=1.700986]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 62/100 average loss: 0.0101\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000034 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:52<00:00, 35.33it/s, cls=0.923130, reg=156.489521]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 64.01it/s, cls=0.018192, reg=1.697123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 63/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000032 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:52<00:00, 35.37it/s, cls=0.922684, reg=156.079101]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 62.80it/s, cls=0.018178, reg=1.698229]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 64/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000031 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:50<00:00, 35.66it/s, cls=0.922454, reg=155.608186]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 64.23it/s, cls=0.018322, reg=1.707870]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 65/100 average loss: 0.0101\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ“Š Visualized predictions on test images\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_065_001_bags.png\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_065_002_camera1.png\n",
      "\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000029 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:50<00:00, 35.58it/s, cls=0.923265, reg=155.881851]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 64.24it/s, cls=0.018212, reg=1.696594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 66/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000028 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:51<00:00, 35.53it/s, cls=0.920207, reg=155.930350]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 63.70it/s, cls=0.018185, reg=1.695682]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 67/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000027 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:51<00:00, 35.51it/s, cls=0.918481, reg=154.795717]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 62.22it/s, cls=0.018103, reg=1.688278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 68/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000025 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:51<00:00, 35.54it/s, cls=0.916217, reg=154.967197]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 64.21it/s, cls=0.018112, reg=1.689820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 69/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000024 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:52<00:00, 35.35it/s, cls=0.919646, reg=153.950617]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 66.34it/s, cls=0.018151, reg=1.694695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 70/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ“Š Visualized predictions on test images\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_070_001_bags.png\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_070_002_camera1.png\n",
      "\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000023 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:52<00:00, 35.38it/s, cls=0.915671, reg=153.950095]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 63.87it/s, cls=0.018123, reg=1.690580]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 71/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000021 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:52<00:00, 35.39it/s, cls=0.911310, reg=154.086782]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 61.59it/s, cls=0.018137, reg=1.696821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 72/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000020 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:52<00:00, 35.39it/s, cls=0.915063, reg=153.386033]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 65.71it/s, cls=0.018069, reg=1.688562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 73/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000019 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:52<00:00, 35.35it/s, cls=0.913098, reg=152.728800]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 63.32it/s, cls=0.018064, reg=1.688695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 74/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000018 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:51<00:00, 35.48it/s, cls=0.912320, reg=152.492724]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 64.65it/s, cls=0.018079, reg=1.690301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 75/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ“Š Visualized predictions on test images\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_075_001_bags.png\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_075_002_camera1.png\n",
      "\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000017 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:51<00:00, 35.44it/s, cls=0.910102, reg=153.082907]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 62.37it/s, cls=0.018064, reg=1.689998]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 76/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000015 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:52<00:00, 35.36it/s, cls=0.909397, reg=152.631061]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 64.83it/s, cls=0.018024, reg=1.687513]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 77/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000014 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:51<00:00, 35.47it/s, cls=0.911074, reg=152.428521]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 63.83it/s, cls=0.018016, reg=1.685606]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 78/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000013 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:51<00:00, 35.50it/s, cls=0.909899, reg=152.020888]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 61.13it/s, cls=0.018027, reg=1.686543]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 79/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000012 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:51<00:00, 35.43it/s, cls=0.903422, reg=152.262085]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 61.66it/s, cls=0.018078, reg=1.687587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 80/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ“Š Visualized predictions on test images\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_080_001_bags.png\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_080_002_camera1.png\n",
      "\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000011 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:52<00:00, 35.36it/s, cls=0.906912, reg=151.420373]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 63.23it/s, cls=0.018060, reg=1.687899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 81/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000010 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:52<00:00, 35.35it/s, cls=0.904864, reg=151.411789]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 63.62it/s, cls=0.018047, reg=1.687205]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 82/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000010 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:52<00:00, 35.34it/s, cls=0.904113, reg=151.345087]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 62.92it/s, cls=0.018050, reg=1.687750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 83/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000009 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:52<00:00, 35.31it/s, cls=0.903276, reg=151.155794]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 63.12it/s, cls=0.018094, reg=1.691821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 84/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000008 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:52<00:00, 35.35it/s, cls=0.906758, reg=150.860026]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 64.20it/s, cls=0.017965, reg=1.681642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 85/100 average loss: 0.0099\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "  ğŸ“Š Visualized predictions on test images\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_085_001_bags.png\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_085_002_camera1.png\n",
      "\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000007 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:52<00:00, 35.35it/s, cls=0.902267, reg=150.858580]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 62.28it/s, cls=0.018034, reg=1.684583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 86/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000006 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:53<00:00, 35.24it/s, cls=0.902069, reg=150.916281]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 62.61it/s, cls=0.018013, reg=1.683832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 87/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000006 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:52<00:00, 35.30it/s, cls=0.901179, reg=150.678751]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 57.17it/s, cls=0.018086, reg=1.688810]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 88/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000005 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:52<00:00, 35.32it/s, cls=0.903364, reg=150.495328]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 60.82it/s, cls=0.017978, reg=1.679879]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 89/100 average loss: 0.0099\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000004 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:53<00:00, 35.15it/s, cls=0.899763, reg=150.699915]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 62.92it/s, cls=0.018008, reg=1.683815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 90/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ“Š Visualized predictions on test images\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_090_001_bags.png\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_090_002_camera1.png\n",
      "\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000004 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:51<00:00, 35.51it/s, cls=0.898809, reg=150.531149]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 63.63it/s, cls=0.018039, reg=1.686508]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 91/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000003 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:51<00:00, 35.42it/s, cls=0.901141, reg=150.449533]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 63.95it/s, cls=0.018006, reg=1.682240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 92/100 average loss: 0.0099\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000003 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:52<00:00, 35.28it/s, cls=0.899971, reg=150.295883]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 61.27it/s, cls=0.018082, reg=1.687129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 93/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000003 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:53<00:00, 35.22it/s, cls=0.905113, reg=150.831916]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 65.21it/s, cls=0.017992, reg=1.680864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 94/100 average loss: 0.0099\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000002 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:53<00:00, 35.23it/s, cls=0.901688, reg=149.900997]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 62.73it/s, cls=0.018001, reg=1.679761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 95/100 average loss: 0.0099\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/ssdlite/best.pt\n",
      "  ğŸ“Š Visualized predictions on test images\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_095_001_bags.png\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_095_002_camera1.png\n",
      "\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000002 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:53<00:00, 35.22it/s, cls=0.902679, reg=150.379804]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 61.32it/s, cls=0.018012, reg=1.682339]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 96/100 average loss: 0.0099\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000002 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:52<00:00, 35.28it/s, cls=0.902549, reg=149.555867]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 62.86it/s, cls=0.017981, reg=1.680792]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 97/100 average loss: 0.0099\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000001 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:52<00:00, 35.33it/s, cls=0.898758, reg=150.285229]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 60.95it/s, cls=0.018034, reg=1.686389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 98/100 average loss: 0.0100\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000001 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:53<00:00, 35.24it/s, cls=0.901343, reg=150.118203]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 62.41it/s, cls=0.018032, reg=1.682684]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 99/100 average loss: 0.0099\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000001 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8216/8216 [03:52<00:00, 35.36it/s, cls=0.901201, reg=150.235745]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171/171 [00:02<00:00, 60.02it/s, cls=0.018004, reg=1.682809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 100/100 average loss: 0.0099\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/ssdlite/last.pt\n",
      "  ğŸ“Š Visualized predictions on test images\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_100_001_bags.png\n",
      "    âœ… Saved: ./outputs/ssdlite/viz/epoch_100_002_camera1.png\n",
      "--- Training Finished ---\n"
     ]
    }
   ],
   "source": [
    "# --- è®­ç»ƒå¾ªç¯ ---\n",
    "print(\"\\n--- Starting Training ---\")\n",
    "\n",
    "# è®¡ç®—é¢„çƒ­çš„æ€»æ­¥æ•°\n",
    "warmup_steps = WARMUP_EPOCHS * len(train_loader)\n",
    "current_step = START_EPOCH * len(train_loader)\n",
    "\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "    model_fpn.train() # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼\n",
    "    \n",
    "    epoch_loss_cls = 0.0\n",
    "    epoch_loss_reg = 0.0\n",
    "\n",
    "    # è¿›åº¦æ¡ä¿¡æ¯\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    pbar = tqdm(train_loader, desc=f\"  ğŸŸ¢ [Training] lr: {optimizer.param_groups[0]['lr']:.6f} \")\n",
    "    \n",
    "    for i, (imgs, targets, _) in enumerate(pbar):\n",
    "        # --- å­¦ä¹ ç‡é¢„çƒ­é€»è¾‘ ---\n",
    "        if current_step < warmup_steps:\n",
    "            # çº¿æ€§é¢„çƒ­\n",
    "            lr_scale = (current_step + 1) / warmup_steps\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = LEARNING_RATE * lr_scale\n",
    "\n",
    "        # --- æ­£å¸¸è®­ç»ƒæ­¥éª¤ ---\n",
    "        imgs = imgs.to(device)\n",
    "        targets_on_device = [t.to(device) for t in targets]\n",
    "        cls_preds, reg_preds = model_fpn(imgs)\n",
    "        loss_cls, loss_reg = criterion(precomputed_anchors, cls_preds, reg_preds, targets_on_device)\n",
    "        total_loss = loss_cls + loss_reg\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "\n",
    "        # --- æ–°å¢ï¼šæ¢¯åº¦è£å‰ª ---\n",
    "        torch.nn.utils.clip_grad_norm_(model_fpn.parameters(), max_norm=GRADIENT_CLIP_VAL)\n",
    "        \n",
    "        # æ›´æ–°æ¨¡å‹å‚æ•°\n",
    "        optimizer.step()\n",
    "\n",
    "        # --- æ›´æ–° EMA ---\n",
    "        # æ›´æ–° EMA å’Œæ­¥æ•°è®¡æ•°å™¨\n",
    "        ema.update(model_fpn)\n",
    "        current_step += 1\n",
    "        \n",
    "        epoch_loss_cls += loss_cls.item()\n",
    "        epoch_loss_reg += loss_reg.item()\n",
    "\n",
    "        # æ˜¾ç¤ºå½“å‰è®­ç»ƒä¿¡æ¯\n",
    "        pbar.set_postfix(cls=f\"{epoch_loss_cls:.6f}\", reg=f\"{epoch_loss_reg:.6f}\")\n",
    "    # end-for: è®­ç»ƒç»“æŸ\n",
    "\n",
    "    # æ¯ä¸ª epoch ç»“æŸåï¼Œæ›´æ–°å­¦ä¹ ç‡è°ƒåº¦å™¨\n",
    "    if epoch >= WARMUP_EPOCHS - 1: # -1 æ˜¯å› ä¸º step() åº”åœ¨ optimizer.step() ä¹‹åè°ƒç”¨\n",
    "        scheduler.step()\n",
    "\n",
    "    # æ¯ä¸ª epoch ç»“æŸåï¼Œè¿›è¡ŒéªŒè¯\n",
    "    avg_total_loss, _, _ = evaluate(ema.ema_model, val_loader, criterion, precomputed_anchors, device)\n",
    "\n",
    "    # # EMA Debug\n",
    "    # val_total_online, _, _ = evaluate(model_fpn.eval(), val_loader, criterion, precomputed_anchors, device)\n",
    "    # val_total_ema,    _, _ = evaluate(ema.ema_model,    val_loader, criterion, precomputed_anchors, device)\n",
    "    # print(f\"Epoch {epoch+1}: val_online={val_total_online:.4f}  val_ema={val_total_ema:.4f}\")\n",
    "    # model_fpn.train()  # è®°å¾—åˆ‡å›è®­ç»ƒæ¨¡å¼\n",
    "\n",
    "    # ç”Ÿæˆæœ¬æ¬¡epochæŠ¥å‘Š\n",
    "    print(f\"  ğŸ“œ Epoch {epoch+1}/{EPOCHS} average loss: {avg_total_loss:.4f}\")\n",
    "\n",
    "    # ä¿å­˜ last.pt å’Œ best.pt\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model': model_fpn.state_dict(),\n",
    "        'ema_model': ema.ema_model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'scheduler': scheduler.state_dict(),\n",
    "        'best_val_loss': BEST_VAL_LOSS,\n",
    "    }\n",
    "    \n",
    "    # ä¿å­˜ last.pt\n",
    "    torch.save(checkpoint, last_pt_path)\n",
    "    print(f\"  ğŸ¯ Saved last checkpoint to {last_pt_path}\")\n",
    "    \n",
    "    # å¦‚æœå½“å‰æ˜¯æœ€ä½³æ¨¡å‹ï¼Œåˆ™ä¿å­˜ best.pt\n",
    "    if avg_total_loss < BEST_VAL_LOSS:\n",
    "        BEST_VAL_LOSS = avg_total_loss\n",
    "        checkpoint['best_val_loss'] = BEST_VAL_LOSS # æ›´æ–° checkpoint ä¸­çš„æœ€ä½³æŸå¤±\n",
    "        best_pt_path = os.path.join(WEIGHTS_DIR, \"best.pt\")\n",
    "        torch.save(checkpoint, best_pt_path)\n",
    "        print(f\"  ğŸ‰ New best model found! Saved to {best_pt_path}\")\n",
    "        \n",
    "    # --- æ¯ 5 ä¸ª epochï¼Œå¯è§†åŒ–ä¸€æ¬¡é¢„æµ‹ç»“æœ ---\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"  ğŸ“Š Visualized predictions on test image\")\n",
    "        viz_dir = os.path.join(WEIGHTS_DIR, \"viz\")\n",
    "        os.makedirs(viz_dir, exist_ok=True)\n",
    "\n",
    "        # 1) åŠ è½½å›¾ç‰‡\n",
    "        import cv2\n",
    "        img_bgr = cv2.imread(TEST_IMAGE_PATH)\n",
    "        if img_bgr is None:\n",
    "            raise FileNotFoundError(f\"TEST_IMAGE_PATH not found: {TEST_IMAGE_PATH}\")\n",
    "        \n",
    "        # éç­‰æ¯”ä¾‹ç›´æ¥æ‹‰ä¼¸\n",
    "        img_resized = cv2.resize(img_bgr, (600, 600), interpolation=cv2.INTER_LINEAR)  \n",
    "\n",
    "        # 2) å¯è§†åŒ–ä¿å­˜å æ¡†ç»“æœ\n",
    "        save_path = os.path.join(viz_dir, f\"epoch_{epoch+1:03d}.png\")\n",
    "        visualize_ssdlite(\n",
    "            model=ema.ema_model,\n",
    "            image=img_resized,                  # ç”¨ç¼©æ”¾åçš„å›¾ç‰‡\n",
    "            device=device,\n",
    "            precomputed_anchors=precomputed_anchors,\n",
    "            conf_thresh=0.5,\n",
    "            nms_thresh=0.45,\n",
    "            save_path=save_path,                # ä¿å­˜ï¼Œä¸ show\n",
    "            draw_on_orig=True,                  # æ³¨æ„ï¼šæ–°å‚æ•°å\n",
    "            show=False\n",
    "        )\n",
    "            \n",
    "print(\"--- Training Finished ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparrow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
