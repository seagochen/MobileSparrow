{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac2ddc9e",
   "metadata": {},
   "source": [
    "# SSDLite 训练笔记（seed）\n",
    "\n",
    "## 0. Imports & 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d6c6f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, time, json\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# === 你工程里的模块 ===\n",
    "from sparrow.models.ssdlite import SSDLite                      # 模型骨架/头/neck  :contentReference[oaicite:4]{index=4}\n",
    "from sparrow.datasets.coco_dets import create_dets_dataloader   # COCO det dataloader  :contentReference[oaicite:5]{index=5}\n",
    "from sparrow.loss.ssdlite_loss import  (\n",
    "    SSDLoss, pack_targets_for_ssd, generate_ssd_anchors,\n",
    ")                                                               # 损失/锚框/编码  :contentReference[oaicite:6]{index=6}\n",
    "\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- 训练配置（可按需改）---\n",
    "IMG_SIZE      = 320\n",
    "BATCH_SIZE    = 64\n",
    "EPOCHS        = 10\n",
    "NUM_WORKERS   = 8\n",
    "PIN_MEMORY    = True\n",
    "DATA_ROOT     = \"./data/coco2017_ssdlite\"   # 根目录，含 images/{train2017,val2017} & annotations/*.json\n",
    "SAVE_DIR      = \"./output/ssdlite\"\n",
    "BACKBONE      = \"mobilenet_v2\"\n",
    "WIDTH_MULT    = 1.0               # 与你选的权重/算力匹配\n",
    "NUM_CLASSES   = 81                # 含背景=1..80（COCO）\n",
    "RATIOS        = (1.0, 2.0, 0.5)\n",
    "SCALES        = (1.0, 1.26)\n",
    "STRIDES       = (8, 16, 32)       # 与默认 SSDLite 配置一致  :contentReference[oaicite:7]{index=7}\n",
    "\n",
    "# 优化器 & 训练细节\n",
    "LR            = 3e-3\n",
    "WD            = 5e-4\n",
    "WARMUP_EPOCHS = 3\n",
    "AMP           = True              # 混合精度\n",
    "NEG_POS_RATIO = 3                 # OHEM 负正比  :contentReference[oaicite:8]{index=8}\n",
    "\n",
    "Path(SAVE_DIR).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1dc4cc",
   "metadata": {},
   "source": [
    "## 1. DataLoader（训练/验证）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dd19468",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_cfg = dict(\n",
    "    use_color_aug=True, use_flip=True, use_rotate=True, rotate_deg=15.0,\n",
    "    use_scale=True, scale_range=(0.75, 1.25), min_box_size=2.0\n",
    ")\n",
    "\n",
    "train_loader: DataLoader = create_dets_dataloader(\n",
    "    dataset_root=DATA_ROOT, img_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, aug_cfg=aug_cfg, is_train=True\n",
    ")  # 训练默认带几何/颜色增广等  :contentReference[oaicite:9]{index=9}\n",
    "\n",
    "val_loader: DataLoader = create_dets_dataloader(\n",
    "    dataset_root=DATA_ROOT, img_size=IMG_SIZE, batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY, aug_cfg=dict(min_box_size=2.0), is_train=False\n",
    ")  # 验证关闭大部分增广  :contentReference[oaicite:10]{index=10}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf1d810",
   "metadata": {},
   "source": [
    "## 2. 构建模型 & 优化器/损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "073221e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SSDLite(\n",
    "    num_classes=NUM_CLASSES, backbone=BACKBONE, width_mult=WIDTH_MULT,\n",
    "    anchor_ratios=RATIOS, anchor_scales=SCALES, anchor_strides=STRIDES\n",
    ").to(DEVICE)  # 输出三层 [P3,P4,P5]，每层 SSDLiteHead 产出 [B, H*W*A, C] 与 [B, H*W*A, 4]  :contentReference[oaicite:11]{index=11}\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9, weight_decay=WD)\n",
    "lr_sched  = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "scaler    = GradScaler(enabled=AMP)\n",
    "\n",
    "# 含背景的 SSDLoss（CrossEntropy + SmoothL1 + OHEM）\n",
    "criterion = SSDLoss(num_classes=NUM_CLASSES, alpha=1.0, neg_pos_ratio=NEG_POS_RATIO, reg_type=\"smoothl1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffbab75",
   "metadata": {},
   "source": [
    "## 3. 预先计算 anchors（按实际特征图尺寸）\n",
    "\n",
    "> 我们用一个 dummy batch 前向，拿到 P3/P4/P5 的 `H,W`，再用 **与训练一致的 strides/ratios/scales** 生成**归一化 (cx,cy,w,h)** anchors；这与损失里的编码/解码严格对齐（variances=(0.1,0.2)）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e14ccb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_shapes: [(80, 80), (40, 40), (20, 20)]  anchors: 50400\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def infer_feat_shapes_and_make_anchors(model, img_size: int):\n",
    "    model.eval()\n",
    "    dummy = torch.zeros(1, 3, img_size, img_size, device=DEVICE)\n",
    "    out = model(dummy)\n",
    "    # 从 cls_logits 每层长度反推出 H*W*A，再用 strides 反推 H,W（已知 A=len(ratios)*len(scales)）\n",
    "    A = len(RATIOS) * len(SCALES)\n",
    "    feat_shapes = []\n",
    "    for cls in out[\"cls_logits\"]:\n",
    "        _, NA, _ = cls.shape\n",
    "        HW = NA // A\n",
    "        H  = int(round(math.sqrt(HW)))\n",
    "        W  = HW // H\n",
    "        feat_shapes.append((H, W))\n",
    "    anchors = generate_ssd_anchors(\n",
    "        img_size=img_size, feat_shapes=feat_shapes, strides=list(STRIDES),\n",
    "        ratios=RATIOS, scales=SCALES\n",
    "    ).to(DEVICE)  # [A_total,4], 归一化 cxcywh  :contentReference[oaicite:14]{index=14}\n",
    "    A_total = anchors.shape[0]\n",
    "    print(\"feat_shapes:\", feat_shapes, \" anchors:\", A_total)\n",
    "    return feat_shapes, anchors\n",
    "\n",
    "feat_shapes, anchors_cxcywh = infer_feat_shapes_and_make_anchors(model, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bd6ab8",
   "metadata": {},
   "source": [
    "## 4. 训练循环（与损失接口完全对齐）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbae33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_amp = AMP and (DEVICE == 'cuda')\n",
    "\n",
    "def to_device_packed(packed, device):\n",
    "    \"\"\"把 pack_targets_for_ssd 返回的结构搬到 device。兼容 list[Tensor]/Tensor/其它。\"\"\"\n",
    "    def _move(x):\n",
    "        if torch.is_tensor(x):\n",
    "            return x.to(device, non_blocking=True)\n",
    "        if isinstance(x, (list, tuple)):\n",
    "            return type(x)(_move(t) for t in x)\n",
    "        if isinstance(x, dict):\n",
    "            return {k: _move(v) for k, v in x.items()}\n",
    "        return x\n",
    "    return _move(packed)\n",
    "\n",
    "best_val = 1e9\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    meter = {\"loss\": 0.0, \"cls\": 0.0, \"reg\": 0.0, \"n\": 0}\n",
    "    t0 = time.time()\n",
    "\n",
    "    for imgs, targets_list, _ in train_loader:\n",
    "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        # 1) 打包 targets（先 CPU 产生，再整体搬到 GPU）\n",
    "        packed = pack_targets_for_ssd(targets_list, img_size=IMG_SIZE)\n",
    "        packed = to_device_packed(packed, DEVICE)  # <<< 关键：把 boxes/labels/masks 全搬到同一设备\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        # 2) 仅在 CUDA 下启用 autocast\n",
    "        if use_amp:\n",
    "            ctx = autocast(device_type='cuda', enabled=True)\n",
    "        else:\n",
    "            # cpu 或未启用 AMP 时，给个空上下文\n",
    "            from contextlib import nullcontext\n",
    "            ctx = nullcontext()\n",
    "\n",
    "        with ctx:\n",
    "            out = model(imgs)\n",
    "            cls_logits = torch.cat(out[\"cls_logits\"], dim=1)  # [B, A_total, C]\n",
    "            bbox_regs  = torch.cat(out[\"bbox_regs\"],  dim=1)  # [B, A_total, 4]\n",
    "            assert cls_logits.shape[1] == anchors_cxcywh.shape[0], \"anchors 与输出长度不一致\"\n",
    "\n",
    "            # 3) 损失计算前，确保 anchors 与 logits 在同设备（通常已是 DEVICE）\n",
    "            loss, m = criterion(cls_logits, bbox_regs, anchors_cxcywh, packed)\n",
    "\n",
    "        if use_amp:\n",
    "            # AMP 模式\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            # 非 AMP（如 CPU 或你关闭 AMP）\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        meter[\"loss\"] += float(loss.detach().cpu())\n",
    "        meter[\"cls\"]  += m[\"loss_cls\"]\n",
    "        meter[\"reg\"]  += m[\"loss_reg\"]\n",
    "        meter[\"n\"]    += 1\n",
    "\n",
    "    lr_sched.step()\n",
    "    dt = time.time() - t0\n",
    "    tr_log = {k: v / max(1, meter[\"n\"]) for k, v in meter.items() if k != \"n\"}\n",
    "    print(f\"[Epoch {epoch:03d}] train: {tr_log}  time={dt:.1f}s  lr={optimizer.param_groups[0]['lr']:.3e}\")\n",
    "\n",
    "    # ---------------- 验证 ----------------\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        vm = {\"loss\": 0.0, \"cls\": 0.0, \"reg\": 0.0, \"n\": 0}\n",
    "        for imgs, targets_list, _ in val_loader:\n",
    "            imgs = imgs.to(DEVICE, non_blocking=True)\n",
    "            packed = pack_targets_for_ssd(targets_list, img_size=IMG_SIZE)\n",
    "            packed = to_device_packed(packed, DEVICE)  # <<< 同样要搬\n",
    "\n",
    "            out = model(imgs)\n",
    "            cls_logits = torch.cat(out[\"cls_logits\"], dim=1)\n",
    "            bbox_regs  = torch.cat(out[\"bbox_regs\"],  dim=1)\n",
    "            loss, m = criterion(cls_logits, bbox_regs, anchors_cxcywh, packed)\n",
    "\n",
    "            vm[\"loss\"] += float(loss.detach().cpu())\n",
    "            vm[\"cls\"]  += m[\"loss_cls\"]\n",
    "            vm[\"reg\"]  += m[\"loss_reg\"]\n",
    "            vm[\"n\"]    += 1\n",
    "\n",
    "        val_log = {k: v / max(1, vm[\"n\"]) for k, v in vm.items() if k != \"n\"}\n",
    "    print(f\"[Epoch {epoch:03d}] valid: {val_log}\")\n",
    "\n",
    "    if val_log[\"loss\"] < best_val:\n",
    "        best_val = val_log[\"loss\"]\n",
    "        ckpt = {\"model_state\": model.state_dict(), \"epoch\": epoch, \"best_score\": best_val}\n",
    "        torch.save(ckpt, f\"{SAVE_DIR}/best.pt\")\n",
    "        print(f\"  ✓ saved best to {SAVE_DIR}/best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562d7fa3",
   "metadata": {},
   "source": [
    "## 5. 简易推理/可视化（验证 anchor/解码逻辑）\n",
    "\n",
    "> 解码要与训练**同一套** variances 与 anchor 定义，直接复用 `decode_deltas_to_xyxy`；运行在 **letterbox 坐标**，再按比例映射回原图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e312471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from sparrow.loss.ssdlite_loss import decode_deltas_to_xyxy  # 与训练同源  :contentReference[oaicite:19]{index=19}\n",
    "\n",
    "def nms_np(boxes, scores, iou=0.5, max_det=100):\n",
    "    order = scores.argsort()[::-1]\n",
    "    keep = []\n",
    "    while order.size > 0 and len(keep) < max_det:\n",
    "        i = order[0]; keep.append(i)\n",
    "        if order.size == 1: break\n",
    "        xx1 = np.maximum(boxes[i,0], boxes[order[1:],0])\n",
    "        yy1 = np.maximum(boxes[i,1], boxes[order[1:],1])\n",
    "        xx2 = np.minimum(boxes[i,2], boxes[order[1:],2])\n",
    "        yy2 = np.minimum(boxes[i,3], boxes[order[1:],3])\n",
    "        w = np.clip(xx2-xx1, 0, None); h = np.clip(yy2-yy1, 0, None)\n",
    "        inter = w*h\n",
    "        area_i = (boxes[i,2]-boxes[i,0])*(boxes[i,3]-boxes[i,1])\n",
    "        area_o = (boxes[order[1:],2]-boxes[order[1:],0])*(boxes[order[1:],3]-boxes[order[1:],1])\n",
    "        ovr = inter / (area_i + area_o - inter + 1e-6)\n",
    "        order = order[1:][ovr < iou]\n",
    "    return np.array(keep, dtype=np.int64)\n",
    "\n",
    "@torch.no_grad()\n",
    "def infer_one(img_bgr, model, conf_thr=0.35, person_idx=1):\n",
    "    # letterbox 到 IMG_SIZE（与训练一致）\n",
    "    h0, w0 = img_bgr.shape[:2]\n",
    "    scale = min(IMG_SIZE/h0, IMG_SIZE/w0)\n",
    "    nh, nw = int(round(h0*scale)), int(round(w0*scale))\n",
    "    canvas = np.full((IMG_SIZE, IMG_SIZE, 3), 114, dtype=np.uint8)\n",
    "    top, left = (IMG_SIZE-nh)//2, (IMG_SIZE-nw)//2\n",
    "    canvas[top:top+nh, left:left+nw] = cv2.resize(img_bgr, (nw, nh))\n",
    "    rgb = cv2.cvtColor(canvas, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    inp = torch.from_numpy(rgb.transpose(2,0,1)).float().unsqueeze(0)/255.0\n",
    "    inp = inp.to(DEVICE)\n",
    "\n",
    "    out = model(inp)\n",
    "    cls = torch.cat(out[\"cls_logits\"], dim=1)  # [1,A,C]\n",
    "    reg = torch.cat(out[\"bbox_regs\"],  dim=1)  # [1,A,4]\n",
    "\n",
    "    probs = torch.softmax(cls[0], dim=-1)      # **含背景 softmax**\n",
    "    deltas = reg[0]\n",
    "    # 解码回归：anchors 是 **归一化(cxcywh)**，得到 **归一化 xyxy**\n",
    "    xyxy_norm = decode_deltas_to_xyxy(deltas, anchors_cxcywh)  # [A,4]  :contentReference[oaicite:20]{index=20}\n",
    "\n",
    "    # 取人类概率（person=1），阈值过滤、NMS\n",
    "    scores = probs[:, person_idx].detach().cpu().numpy()\n",
    "    mask = scores >= conf_thr\n",
    "    boxes_lbox = xyxy_norm[mask].detach().cpu().numpy() * IMG_SIZE  # 回到 letterbox 像素\n",
    "    scores = scores[mask]\n",
    "    if boxes_lbox.shape[0] > 0:\n",
    "        keep = nms_np(boxes_lbox, scores, iou=0.5, max_det=100)\n",
    "        boxes_lbox, scores = boxes_lbox[keep], scores[keep]\n",
    "\n",
    "    # 映回原图\n",
    "    boxes = []\n",
    "    for (x1,y1,x2,y2) in boxes_lbox:\n",
    "        X1 = (x1 - left) / scale\n",
    "        Y1 = (y1 - top ) / scale\n",
    "        X2 = (x2 - left) / scale\n",
    "        Y2 = (y2 - top ) / scale\n",
    "        boxes.append([X1,Y1,X2,Y2])\n",
    "    return np.array(boxes, np.float32), scores\n",
    "\n",
    "# 可视化\n",
    "img = cv2.imread(\"./india_road.png\")\n",
    "boxes, scores = infer_one(img, model, conf_thr=0.35, person_idx=1)\n",
    "vis = img.copy()\n",
    "for b,s in zip(boxes.astype(int), scores):\n",
    "    cv2.rectangle(vis, (b[0],b[1]), (b[2],b[3]), (0,200,255), 2)\n",
    "    cv2.putText(vis, f\"{s:.2f}\", (b[0], max(0,b[1]-4)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,200,255), 1, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e0ecfe",
   "metadata": {},
   "source": [
    "## 为什么这套 note 能“稳”\n",
    "\n",
    "* **类别定义**：数据集把 COCO 类别映射为 **0..C-1 连续索引**（人常为 0）；损失里**背景=0**，前景标签范围被内部处理为 **1..C-1**，因此**模型 num\\_classes 必须= C+1 = 81**，并用 **softmax**。这一点在 `SSDLoss` 的文档与实现里写得很清楚（编码/解码 variances = 0.1/0.2；OHEM 负样本挖掘也依赖背景通道的 CE）。&#x20;\n",
    "* **锚框/解码一致**：训练/推理均使用 `generate_ssd_anchors` 的**归一化 cxcywh**，配合同一个 `decode_deltas_to_xyxy`，不会再出现“anchor/stride/variance 不一致”的偏差。\n",
    "* **特征尺寸对齐**：先跑一次前向，自动推断 `[P3,P4,P5]` 的 `(H,W)`，结合 `A=len(ratios)*len(scales)` 与 `STRIDES=(8,16,32)` 生成 anchors，长度与 head 展平维度严格一致（我们也加了 assert）。\n",
    "* **DataLoader 与增广**：与你工程现有的增广/letterbox 完全一致，验证集关闭大部分增广，避免评测偏差。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparrow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
