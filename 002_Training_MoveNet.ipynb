{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c77219de",
   "metadata": {},
   "source": [
    "# MoveNet_FPN è®­ç»ƒç¬”è®°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c3c530",
   "metadata": {},
   "source": [
    "## å¯¼å…¥å·¥ç¨‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ccc7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cxt/miniconda3/envs/sparrow/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥ç³»ç»Ÿåº“\n",
    "import os\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# å¯¼å…¥sparrow\n",
    "from sparrow.models.movenet_fpn import MoveNet_FPN, decode_movenet_outputs\n",
    "from sparrow.datasets.coco_kpts import create_kpts_dataloader\n",
    "from sparrow.losses.movenet_loss import MoveNetLoss, evaluate\n",
    "from sparrow.utils.ema import EMA\n",
    "from sparrow.utils.visual_movenet import visualize_movenet\n",
    "\n",
    "# å¯¼å…¥torchåº“\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0c5166",
   "metadata": {},
   "source": [
    "## å‚æ•°è®¾ç½®\n",
    "\n",
    "### ç³»ç»Ÿå‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2164b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "INPUT_SIZE = 192\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 4\n",
    "NUM_JOINTS = 17\n",
    "UPSAMPLE = True\n",
    "TARGET_STRIDE=4\n",
    "\n",
    "COCO_ROOT = \"./data/coco2017_movenet\"       # COCOè®­ç»ƒæ•°æ®é›†\n",
    "WEIGHTS_DIR = \"./outputs/movenet\"           # ä¿å­˜æƒé‡çš„ç›®å½•\n",
    "TEST_IMAGE_PATH = \"./res/girl_with_bags.png\"    # æµ‹è¯•å›¾ç‰‡è·¯å¾„"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c152cc",
   "metadata": {},
   "source": [
    "### å­¦ä¹ å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426df7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_EPOCH = 0\n",
    "EPOCHS=100                      # è®­ç»ƒæ¬¡æ•°\n",
    "BEST_VAL_LOSS = float('inf')\n",
    "# LEARNING_RATE = 1e-4            # åˆå§‹å­¦ä¹ ç‡\n",
    "# WEIGHT_DECAY = 1e-3\n",
    "WARMUP_EPOCHS = 2               # é¢„çƒ­\n",
    "GRADIENT_CLIP_VAL = 5.0         # æ¢¯åº¦è£å‰ªçš„é˜ˆå€¼\n",
    "\n",
    "LEARNING_RATE = 3e-4         # from 1e-4 -> 3e-4\n",
    "WEIGHT_DECAY  = 1e-4         # from 1e-3 -> 1e-4 (æˆ– 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea85236",
   "metadata": {},
   "source": [
    "## åˆ›å»ºæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f565b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    }
   ],
   "source": [
    "backbone_fpn = timm.create_model('mobilenetv3_large_100', pretrained=True, features_only=True, out_indices=(2, 3, 4))\n",
    "model_fpn = MoveNet_FPN(backbone_fpn, num_joints=NUM_JOINTS, fpn_out_channels=128, upsample_to_quarter=UPSAMPLE)\n",
    "model_fpn.to(device)\n",
    "\n",
    "# EMAè¯„ä¼°å™¨\n",
    "ema = EMA(model_fpn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ffb45d",
   "metadata": {},
   "source": [
    "## åŠ è½½æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ebda0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cxt/projects/MobileSparrow/sparrow/datasets/coco_kpts.py:128: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  transforms.append(A.PadIfNeeded(\n",
      "/home/cxt/miniconda3/envs/sparrow/lib/python3.10/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/home/cxt/projects/MobileSparrow/sparrow/datasets/coco_kpts.py:141: UserWarning: Argument(s) 'value' are not valid for transform ShiftScaleRotate\n",
      "  transforms.append(A.ShiftScaleRotate(\n"
     ]
    }
   ],
   "source": [
    "# åˆ›å»ºè®­ç»ƒæ•°æ®åŠ è½½å™¨ (æ¥è‡ª dataloader.py)\n",
    "train_aug_config = { \"use_flip\": True, \"use_color_aug\": True }\n",
    "train_loader = create_kpts_dataloader(\n",
    "    dataset_root=COCO_ROOT,\n",
    "    img_size=INPUT_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    target_stride=TARGET_STRIDE,\n",
    "    pin_memory=True,\n",
    "    aug_cfg=train_aug_config,\n",
    "    is_train=True\n",
    ")\n",
    "\n",
    "# åˆ›å»ºéªŒè¯é›†æ•°æ®åŠ è½½å™¨\n",
    "test_aug_config = {\"use_flip\": True}\n",
    "val_loader = create_kpts_dataloader(\n",
    "    dataset_root=COCO_ROOT,\n",
    "    img_size=INPUT_SIZE,\n",
    "    batch_size=BATCH_SIZE * 2,  # éªŒè¯æ—¶é€šå¸¸å¯ä»¥ç”¨æ›´å¤§çš„ batch size\n",
    "    num_workers=NUM_WORKERS,\n",
    "    target_stride=TARGET_STRIDE,\n",
    "    pin_memory=True,\n",
    "    aug_cfg=test_aug_config,\n",
    "    is_train=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb7fda2",
   "metadata": {},
   "source": [
    "## æŸå¤±ä¼˜åŒ–è°ƒåº¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2f4e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸå¤±å‡½æ•°\n",
    "# criterion = MoveNetLoss(reg_weight=2.0, off_weight=1.0)\n",
    "criterion = MoveNetLoss(hm_weight=1.0, ct_weight=1.0, reg_weight=1.5, off_weight=1.0)\n",
    "\n",
    "# ä¼˜åŒ–å™¨\n",
    "# optimizer = torch.optim.AdamW(model_fpn.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "optimizer = torch.optim.Adam(  # Adam æ›´å®½æ¾ï¼›è‹¥ç»§ç»­ç”¨ AdamW ä¹Ÿè¡Œ\n",
    "    model_fpn.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "# å­¦ä¹ è°ƒåº¦å™¨\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7b845f",
   "metadata": {},
   "source": [
    "## åŠ è½½é¢„è®­ç»ƒæƒé‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd5743c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¡®ä¿å­˜æ”¾é¢„è®­ç»ƒçš„ç›®å½•å­˜åœ¨\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True) # ç¡®ä¿ç›®å½•å­˜åœ¨\n",
    "\n",
    "# æ–­ç‚¹ç»­è®­é€»è¾‘\n",
    "last_pt_path = os.path.join(WEIGHTS_DIR, \"last.pt\")\n",
    "if os.path.exists(last_pt_path):\n",
    "    print(\"--- Resuming training from last.pt ---\")\n",
    "\n",
    "    # åŠ è½½ptæ–‡ä»¶\n",
    "    checkpoint = torch.load(last_pt_path, map_location=device)\n",
    "    \n",
    "    # ä»ptä¸­è¯»å–æ¨¡å‹æƒé‡\n",
    "    model_fpn.load_state_dict(checkpoint['model'])\n",
    "    \n",
    "    # åŠ è½½EMAçŠ¶æ€\n",
    "    ema.ema_model.load_state_dict(checkpoint['ema_model'])\n",
    "\n",
    "    # åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "    # åŠ è½½è°ƒåº¦å™¨çŠ¶æ€\n",
    "    scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "\n",
    "    # æ›´æ–°EPOCHçŠ¶æ€\n",
    "    START_EPOCH = checkpoint['epoch'] + 1\n",
    "    \n",
    "    # æ›´æ–°æœ€ä½³æŸå¤±çŠ¶æ€\n",
    "    BEST_VAL_LOSS = checkpoint['best_val_loss']\n",
    "    \n",
    "    # æ‰“å°ç¡®è®¤æ¶ˆæ¯\n",
    "    print(f\"Resumed from epoch {START_EPOCH-1}. Best validation loss so far: {BEST_VAL_LOSS:.4f}\")\n",
    "    print(f\"Current learning rate is {optimizer.param_groups[0]['lr']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353631e5",
   "metadata": {},
   "source": [
    "## è®­ç»ƒå¾ªç¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a64177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Training ---\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000100 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16220/16220 [04:55<00:00, 54.82it/s, center=43.66, hm=95.31, offsets=6882.29, regs=32410.39]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:05<00:00, 61.68it/s, ct=0.706919, hm=0.248512, off=84.057418, pck=11.28%, reg=567.797134, tot=1220.607111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 1/100 average loss: 3.5900\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/movenet/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/movenet/best.pt\n",
      "\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000050 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16220/16220 [04:48<00:00, 56.31it/s, center=32.65, hm=11.61, offsets=3946.55, regs=27308.93]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:06<00:00, 50.88it/s, ct=0.688918, hm=0.238077, off=81.188602, pck=10.76%, reg=542.902588, tot=1167.920774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 2/100 average loss: 3.4351\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/movenet/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/movenet/best.pt\n",
      "\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000100 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16220/16220 [04:51<00:00, 55.60it/s, center=31.74, hm=11.33, offsets=3875.22, regs=26219.12]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:07<00:00, 46.65it/s, ct=0.671145, hm=0.233503, off=80.145960, pck=13.20%, reg=529.805649, tot=1140.661907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 3/100 average loss: 3.3549\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/movenet/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/movenet/best.pt\n",
      "\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000100 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16220/16220 [04:49<00:00, 55.98it/s, center=31.36, hm=11.17, offsets=3844.81, regs=25593.73]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:07<00:00, 46.93it/s, ct=0.668420, hm=0.231180, off=79.715498, pck=14.45%, reg=529.605000, tot=1139.825097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 4/100 average loss: 3.3524\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/movenet/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/movenet/best.pt\n",
      "\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000100 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16220/16220 [04:49<00:00, 56.08it/s, center=31.16, hm=11.08, offsets=3825.33, regs=25222.87]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:07<00:00, 44.78it/s, ct=0.663141, hm=0.230199, off=79.367148, pck=14.54%, reg=526.820862, tot=1133.902211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 5/100 average loss: 3.3350\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/movenet/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/movenet/best.pt\n",
      "  ğŸ“Š Visualized predictions on test image\n",
      "\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000100 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16220/16220 [04:51<00:00, 55.72it/s, center=31.06, hm=11.02, offsets=3816.24, regs=24987.40]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:07<00:00, 44.66it/s, ct=0.662178, hm=0.228614, off=79.138452, pck=14.68%, reg=527.886556, tot=1135.802358]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 6/100 average loss: 3.3406\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/movenet/last.pt\n",
      "\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000099 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16220/16220 [04:46<00:00, 56.68it/s, center=30.92, hm=10.98, offsets=3809.99, regs=24795.22]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:07<00:00, 45.06it/s, ct=0.654661, hm=0.228206, off=78.949096, pck=14.43%, reg=529.151944, tot=1138.135852]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 7/100 average loss: 3.3475\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/movenet/last.pt\n",
      "\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000099 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16220/16220 [04:48<00:00, 56.19it/s, center=30.86, hm=10.93, offsets=3802.31, regs=24595.43]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:07<00:00, 43.61it/s, ct=0.655297, hm=0.227600, off=78.784068, pck=15.38%, reg=522.620069, tot=1124.907103]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 8/100 average loss: 3.3086\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/movenet/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/movenet/best.pt\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000099 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16220/16220 [04:50<00:00, 55.90it/s, center=30.81, hm=10.91, offsets=3796.86, regs=24476.32]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:07<00:00, 45.25it/s, ct=0.653749, hm=0.226525, off=78.636585, pck=15.08%, reg=519.870103, tot=1119.257067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 9/100 average loss: 3.2919\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/movenet/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/movenet/best.pt\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000098 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16220/16220 [04:58<00:00, 54.37it/s, center=30.69, hm=10.88, offsets=3795.29, regs=24319.43]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:07<00:00, 42.58it/s, ct=0.654503, hm=0.226674, off=78.485995, pck=15.68%, reg=518.867667, tot=1117.102509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 10/100 average loss: 3.2856\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/movenet/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/movenet/best.pt\n",
      "  ğŸ“Š Visualized predictions on test image\n",
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000098 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16220/16220 [04:46<00:00, 56.53it/s, center=30.69, hm=10.86, offsets=3790.36, regs=24193.75]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:07<00:00, 44.70it/s, ct=0.650639, hm=0.226193, off=78.449866, pck=15.46%, reg=520.358190, tot=1120.043079]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 11/100 average loss: 3.2942\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/movenet/last.pt\n",
      "\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000098 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16220/16220 [04:54<00:00, 55.03it/s, center=30.59, hm=10.85, offsets=3787.01, regs=24105.17]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:07<00:00, 45.46it/s, ct=0.651415, hm=0.226204, off=78.370030, pck=15.95%, reg=522.753983, tot=1124.755614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 12/100 average loss: 3.3081\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/movenet/last.pt\n",
      "\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000097 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16220/16220 [04:49<00:00, 56.10it/s, center=30.54, hm=10.83, offsets=3780.17, regs=23985.45]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:07<00:00, 44.35it/s, ct=0.649337, hm=0.225954, off=78.281934, pck=15.73%, reg=521.433879, tot=1122.024985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 13/100 average loss: 3.3001\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/movenet/last.pt\n",
      "\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000097 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16220/16220 [04:48<00:00, 56.15it/s, center=30.52, hm=10.83, offsets=3776.45, regs=23893.63]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:07<00:00, 44.73it/s, ct=0.649652, hm=0.225686, off=78.250483, pck=15.63%, reg=517.849880, tot=1114.825584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 14/100 average loss: 3.2789\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/movenet/last.pt\n",
      "  ğŸ‰ New best model found! Saved to ./outputs/movenet/best.pt\n",
      "\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000096 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16220/16220 [04:48<00:00, 56.13it/s, center=30.53, hm=10.83, offsets=3775.63, regs=23792.64]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:07<00:00, 42.89it/s, ct=0.648805, hm=0.225543, off=78.210124, pck=16.40%, reg=521.367825, tot=1121.820127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 15/100 average loss: 3.2995\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/movenet/last.pt\n",
      "  ğŸ“Š Visualized predictions on test image\n",
      "\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000095 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16220/16220 [04:47<00:00, 56.46it/s, center=30.51, hm=10.81, offsets=3771.41, regs=23693.75]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:08<00:00, 42.49it/s, ct=0.650102, hm=0.225398, off=78.107334, pck=15.15%, reg=522.000938, tot=1122.984713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 16/100 average loss: 3.3029\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/movenet/last.pt\n",
      "\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000095 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16220/16220 [04:46<00:00, 56.54it/s, center=30.47, hm=10.80, offsets=3769.40, regs=23644.88]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:07<00:00, 43.96it/s, ct=0.645728, hm=0.225001, off=78.099929, pck=15.80%, reg=520.846692, tot=1120.664047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 17/100 average loss: 3.2961\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/movenet/last.pt\n",
      "\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000094 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16220/16220 [04:54<00:00, 55.01it/s, center=30.45, hm=10.80, offsets=3768.65, regs=23544.09]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:08<00:00, 42.04it/s, ct=0.646685, hm=0.225229, off=78.064404, pck=16.05%, reg=521.687961, tot=1122.312239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 18/100 average loss: 3.3009\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/movenet/last.pt\n",
      "\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000093 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16220/16220 [04:54<00:00, 55.06it/s, center=30.43, hm=10.79, offsets=3768.62, regs=23450.19]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:07<00:00, 45.24it/s, ct=0.647459, hm=0.225418, off=78.021966, pck=15.57%, reg=525.462846, tot=1129.820534]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 19/100 average loss: 3.3230\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/movenet/last.pt\n",
      "\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000092 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16220/16220 [04:49<00:00, 55.99it/s, center=30.42, hm=10.79, offsets=3764.65, regs=23382.52]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:07<00:00, 44.19it/s, ct=0.646402, hm=0.225351, off=78.029534, pck=15.66%, reg=523.907374, tot=1126.716038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 20/100 average loss: 3.3139\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/movenet/last.pt\n",
      "  ğŸ“Š Visualized predictions on test image\n",
      "\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000091 : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16220/16220 [04:51<00:00, 55.61it/s, center=30.39, hm=10.78, offsets=3763.94, regs=23314.30]\n",
      "  ğŸŸ¡ [Validating] : 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:08<00:00, 42.25it/s, ct=0.648435, hm=0.225190, off=78.050951, pck=15.76%, reg=524.754231, tot=1128.433037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“œ Epoch 21/100 average loss: 3.3189\n",
      "  ğŸ¯ Saved last checkpoint to ./outputs/movenet/last.pt\n",
      "\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ğŸŸ¢ [Training] lr: 0.000091 :  23%|â–ˆâ–ˆâ–       | 3683/16220 [01:06<03:47, 55.03it/s, center=6.90, hm=2.45, offsets=854.25, regs=5281.43]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# æ›´æ–°EMA\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[43mema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_fpn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m current_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     54\u001b[0m epoch_loss_center \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_center\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/sparrow/lib/python3.10/site-packages/torch/utils/_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/MobileSparrow/sparrow/utils/ema.py:68\u001b[0m, in \u001b[0;36mEMA.update\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# 1) å‚æ•°åš EMA\u001b[39;00m\n\u001b[1;32m     67\u001b[0m msd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(model\u001b[38;5;241m.\u001b[39mnamed_parameters())\n\u001b[0;32m---> 68\u001b[0m esd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mema_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamed_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, p \u001b[38;5;129;01min\u001b[39;00m msd\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mrequires_grad:\n",
      "File \u001b[0;32m~/miniconda3/envs/sparrow/lib/python3.10/site-packages/torch/nn/modules/module.py:2706\u001b[0m, in \u001b[0;36mModule.named_parameters\u001b[0;34m(self, prefix, recurse, remove_duplicate)\u001b[0m\n\u001b[1;32m   2679\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return an iterator over module parameters, yielding both the name of the parameter as well as the parameter itself.\u001b[39;00m\n\u001b[1;32m   2680\u001b[0m \n\u001b[1;32m   2681\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2698\u001b[0m \n\u001b[1;32m   2699\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2700\u001b[0m gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_named_members(\n\u001b[1;32m   2701\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m module: module\u001b[38;5;241m.\u001b[39m_parameters\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   2702\u001b[0m     prefix\u001b[38;5;241m=\u001b[39mprefix,\n\u001b[1;32m   2703\u001b[0m     recurse\u001b[38;5;241m=\u001b[39mrecurse,\n\u001b[1;32m   2704\u001b[0m     remove_duplicate\u001b[38;5;241m=\u001b[39mremove_duplicate,\n\u001b[1;32m   2705\u001b[0m )\n\u001b[0;32m-> 2706\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m gen\n",
      "File \u001b[0;32m~/miniconda3/envs/sparrow/lib/python3.10/site-packages/torch/nn/modules/module.py:2641\u001b[0m, in \u001b[0;36mModule._named_members\u001b[0;34m(self, get_members_fn, prefix, recurse, remove_duplicate)\u001b[0m\n\u001b[1;32m   2635\u001b[0m memo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m   2636\u001b[0m modules \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2637\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_modules(prefix\u001b[38;5;241m=\u001b[39mprefix, remove_duplicate\u001b[38;5;241m=\u001b[39mremove_duplicate)\n\u001b[1;32m   2638\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recurse\n\u001b[1;32m   2639\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m [(prefix, \u001b[38;5;28mself\u001b[39m)]\n\u001b[1;32m   2640\u001b[0m )\n\u001b[0;32m-> 2641\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module_prefix, module \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   2642\u001b[0m     members \u001b[38;5;241m=\u001b[39m get_members_fn(module)\n\u001b[1;32m   2643\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m members:\n",
      "File \u001b[0;32m~/miniconda3/envs/sparrow/lib/python3.10/site-packages/torch/nn/modules/module.py:2863\u001b[0m, in \u001b[0;36mModule.named_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   2861\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   2862\u001b[0m submodule_prefix \u001b[38;5;241m=\u001b[39m prefix \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m name\n\u001b[0;32m-> 2863\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_modules(\n\u001b[1;32m   2864\u001b[0m     memo, submodule_prefix, remove_duplicate\n\u001b[1;32m   2865\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/sparrow/lib/python3.10/site-packages/torch/nn/modules/module.py:2863\u001b[0m, in \u001b[0;36mModule.named_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   2861\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   2862\u001b[0m submodule_prefix \u001b[38;5;241m=\u001b[39m prefix \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m name\n\u001b[0;32m-> 2863\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_modules(\n\u001b[1;32m   2864\u001b[0m     memo, submodule_prefix, remove_duplicate\n\u001b[1;32m   2865\u001b[0m )\n",
      "    \u001b[0;31m[... skipping similar frames: Module.named_modules at line 2863 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/sparrow/lib/python3.10/site-packages/torch/nn/modules/module.py:2863\u001b[0m, in \u001b[0;36mModule.named_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   2861\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   2862\u001b[0m submodule_prefix \u001b[38;5;241m=\u001b[39m prefix \u001b[38;5;241m+\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m name\n\u001b[0;32m-> 2863\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m module\u001b[38;5;241m.\u001b[39mnamed_modules(\n\u001b[1;32m   2864\u001b[0m     memo, submodule_prefix, remove_duplicate\n\u001b[1;32m   2865\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/sparrow/lib/python3.10/site-packages/torch/nn/modules/module.py:2857\u001b[0m, in \u001b[0;36mModule.named_modules\u001b[0;34m(self, memo, prefix, remove_duplicate)\u001b[0m\n\u001b[1;32m   2855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m memo:\n\u001b[1;32m   2856\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m remove_duplicate:\n\u001b[0;32m-> 2857\u001b[0m         \u001b[43mmemo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2858\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m prefix, \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   2859\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- è®­ç»ƒå¾ªç¯ ---\n",
    "print(\"\\n--- Starting Training ---\")\n",
    "\n",
    "# è®¡ç®—é¢„çƒ­çš„æ€»æ­¥æ•°\n",
    "warmup_steps = WARMUP_EPOCHS * len(train_loader)\n",
    "current_step = START_EPOCH * len(train_loader)\n",
    "\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "    model_fpn.train() # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼\n",
    "\n",
    "    epoch_loss_heatmap = 0.0\n",
    "    epoch_loss_center = 0.0\n",
    "    epoch_loss_regs = 0.0\n",
    "    epoch_loss_offsets = 0.0\n",
    "\n",
    "    # è¿›åº¦æ¡ä¿¡æ¯\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    pbar = tqdm(train_loader, desc=f\"  ğŸŸ¢ [Training] lr: {optimizer.param_groups[0]['lr']:.6f} \")\n",
    "\n",
    "    for i, (imgs, labels, kps_masks, _) in enumerate(pbar):\n",
    "    \n",
    "        # å­¦ä¹ ç‡é¢„çƒ­é€»è¾‘\n",
    "        if current_step < warmup_steps:\n",
    "            # çº¿æ€§é¢„çƒ­\n",
    "            lr_scale = (current_step + 1) / warmup_steps\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = LEARNING_RATE * lr_scale\n",
    "        \n",
    "        # æ­£å¸¸è®­ç»ƒæ­¥éª¤\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        kps_masks = kps_masks.to(device)\n",
    "\n",
    "        # å‰å‘ä¼ æ’­\n",
    "        preds = model_fpn(imgs)\n",
    "\n",
    "        # è®¡ç®—æŸå¤±\n",
    "        total_loss, loss_dict = criterion(preds, labels, kps_masks) \n",
    "\n",
    "        # åå‘ä¼ æ’­å’Œä¼˜åŒ–\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "\n",
    "        # æ¢¯åº¦è£å‰ª\n",
    "        torch.nn.utils.clip_grad_norm_(model_fpn.parameters(), max_norm=GRADIENT_CLIP_VAL)\n",
    "        \n",
    "        # æ›´æ–°æ¨¡å‹å‚æ•°\n",
    "        optimizer.step()\n",
    "\n",
    "        # æ›´æ–°EMA\n",
    "        ema.update(model_fpn)\n",
    "        current_step += 1\n",
    "\n",
    "        epoch_loss_center += loss_dict[\"loss_center\"]\n",
    "        epoch_loss_heatmap += loss_dict[\"loss_heatmap\"]\n",
    "        epoch_loss_offsets += loss_dict[\"loss_offsets\"]\n",
    "        epoch_loss_regs += loss_dict[\"loss_regs\"]\n",
    "\n",
    "        # æ˜¾ç¤ºå½“å‰ä¿¡æ¯\n",
    "        pbar.set_postfix(hm=f\"{epoch_loss_heatmap:.2f}\", \n",
    "                         center=f\"{epoch_loss_center:.2f}\", \n",
    "                         offsets=f\"{epoch_loss_offsets:.2f}\",\n",
    "                         regs=f\"{epoch_loss_regs:.2f}\")\n",
    "    # end-for: è®­ç»ƒç»“æŸ\n",
    "\n",
    "    # æ¯ä¸ª epoch ç»“æŸåï¼Œæ›´æ–°å­¦ä¹ ç‡è°ƒåº¦å™¨\n",
    "    if epoch >= WARMUP_EPOCHS - 1: # -1 æ˜¯å› ä¸º step() åº”åœ¨ optimizer.step() ä¹‹åè°ƒç”¨\n",
    "        scheduler.step()\n",
    "\n",
    "    # æ¯ä¸ª epoch ç»“æŸåï¼Œè¿›è¡ŒéªŒè¯\n",
    "    avg_total_loss, _, = evaluate(ema.ema_model, val_loader, criterion, device, decoder=decode_movenet_outputs)\n",
    "\n",
    "    # ç”Ÿæˆæœ¬æ¬¡epochæŠ¥å‘Š\n",
    "    print(f\"  ğŸ“œ Epoch {epoch+1}/{EPOCHS} average loss: {avg_total_loss:.4f}\")\n",
    "\n",
    "    # ä¿å­˜ last.pt å’Œ best.pt\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model': model_fpn.state_dict(),\n",
    "        'ema_model': ema.ema_model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'scheduler': scheduler.state_dict(),\n",
    "        'best_val_loss': BEST_VAL_LOSS,\n",
    "    }\n",
    "\n",
    "    # ä¿å­˜ last.pt\n",
    "    torch.save(checkpoint, last_pt_path)\n",
    "    print(f\"  ğŸ¯ Saved last checkpoint to {last_pt_path}\")\n",
    "    \n",
    "    # å¦‚æœå½“å‰æ˜¯æœ€ä½³æ¨¡å‹ï¼Œåˆ™ä¿å­˜ best.pt\n",
    "    if avg_total_loss < BEST_VAL_LOSS:\n",
    "        BEST_VAL_LOSS = avg_total_loss\n",
    "        checkpoint['best_val_loss'] = BEST_VAL_LOSS # æ›´æ–° checkpoint ä¸­çš„æœ€ä½³æŸå¤±\n",
    "        best_pt_path = os.path.join(WEIGHTS_DIR, \"best.pt\")\n",
    "        torch.save(checkpoint, best_pt_path)\n",
    "        print(f\"  ğŸ‰ New best model found! Saved to {best_pt_path}\")\n",
    "        \n",
    "    # --- æ¯ 5 ä¸ª epochï¼Œå¯è§†åŒ–ä¸€æ¬¡é¢„æµ‹ç»“æœ ---\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"  ğŸ“Š Visualized predictions on test image\")\n",
    "        viz_dir = os.path.join(WEIGHTS_DIR, \"viz\")\n",
    "        os.makedirs(viz_dir, exist_ok=True)\n",
    "\n",
    "        # 1) åŠ è½½å›¾ç‰‡\n",
    "        import cv2\n",
    "        img_bgr = cv2.imread(TEST_IMAGE_PATH)\n",
    "        if img_bgr is None:\n",
    "            raise FileNotFoundError(f\"TEST_IMAGE_PATH not found: {TEST_IMAGE_PATH}\")\n",
    "        \n",
    "        # éç­‰æ¯”ä¾‹ç›´æ¥æ‹‰ä¼¸\n",
    "        img_resized = cv2.resize(img_bgr, (600, 600), interpolation=cv2.INTER_LINEAR)  \n",
    "\n",
    "        # 2) å¯è§†åŒ–ä¿å­˜å æ¡†ç»“æœï¼ˆä¼šå›åˆ°è¿™å¼  800x600 çš„åæ ‡ç³»ä¸Šç»˜åˆ¶ï¼‰\n",
    "        save_path = os.path.join(viz_dir, f\"epoch_{epoch+1:03d}.png\")\n",
    "        visualize_movenet(\n",
    "            model=model_fpn,\n",
    "            image=img_resized,               # æˆ–è€…ä¼ å…¥ np.ndarray(BGR/RGB éƒ½è¡Œï¼Œè¿™é‡Œå†…éƒ¨æŒ‰ RGB å¤„ç†æ˜¾ç¤º)\n",
    "            device=device,\n",
    "            decoder=decode_movenet_outputs, # ç›´æ¥ç”¨ä½ å·²æœ‰çš„è§£ç å™¨\n",
    "            input_size=192,\n",
    "            stride=8,                       # è‹¥æ¨¡å‹æŠŠ P3 ä¸Šé‡‡æ ·åˆ°1/4ï¼Œè¿™é‡Œæ”¹æˆ 4\n",
    "            topk_centers=1,                 # å…ˆåªå–æœ€å¼ºä¸­å¿ƒ\n",
    "            center_thresh=0.25,\n",
    "            keypoint_thresh=0.05,\n",
    "            draw_bbox=True,\n",
    "            draw_skeleton=True,\n",
    "            draw_on_orig=True,              # ç”»åœ¨åŸå›¾ä¸Š\n",
    "            draw_heatmaps=True,\n",
    "            save_path=save_path,    # æˆ– None å¹¶ show=True ç›´æ¥æ˜¾ç¤º\n",
    "            show=False\n",
    "        )\n",
    "            \n",
    "print(\"--- Training Finished ---\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aigc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
