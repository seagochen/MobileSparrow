{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c77219de",
   "metadata": {},
   "source": [
    "# MoveNet_FPN 训练笔记"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1820f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cxt/miniconda3/envs/sparrow/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # MoveNet_FPN 训练笔记\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 导入工程\n",
    "\n",
    "# %%\n",
    "# 导入系统库\n",
    "import os\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 导入sparrow\n",
    "from sparrow.models.movenet_fpn import MoveNet_FPN, decode_movenet_outputs\n",
    "from sparrow.datasets.coco_kpts import create_kpts_dataloader\n",
    "from sparrow.losses.movenet_loss import MoveNetLoss, evaluate_local\n",
    "from sparrow.utils.ema import EMA\n",
    "from sparrow.utils.visual_movenet import visualize_detections\n",
    "\n",
    "# 导入torch库\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "# 其他\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 参数设置\n",
    "#\n",
    "# ### 系统参数\n",
    "\n",
    "# %%\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "INPUT_SIZE = 192\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 4\n",
    "NUM_JOINTS = 17\n",
    "UPSAMPLE = True\n",
    "TARGET_STRIDE = 4\n",
    "\n",
    "COCO_ROOT = \"./data/coco2017_movenet\"            # COCO训练数据集\n",
    "WEIGHTS_DIR = \"./outputs/movenet\"                # 保存权重的目录\n",
    "TEST_IMAGE_PATH = \"./res/girl_with_bags.png\"     # 测试图片路径\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 学习参数\n",
    "\n",
    "# %%\n",
    "START_EPOCH = 0\n",
    "EPOCHS = 100\n",
    "BEST_VAL_LOSS = float('inf')\n",
    "\n",
    "WARMUP_EPOCHS = 2               # 线性预热 epoch 数\n",
    "GRADIENT_CLIP_VAL = 5.0         # 梯度裁剪阈值\n",
    "\n",
    "LEARNING_RATE = 3e-4\n",
    "WEIGHT_DECAY  = 1e-4\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 创建模型\n",
    "\n",
    "# %%\n",
    "backbone_fpn = timm.create_model(\n",
    "    'mobilenetv3_large_100', pretrained=True, features_only=True, out_indices=(2, 3, 4)\n",
    ")\n",
    "model_fpn = MoveNet_FPN(\n",
    "    backbone_fpn,\n",
    "    num_joints=NUM_JOINTS,\n",
    "    fpn_out_channels=128,\n",
    "    upsample_to_quarter=UPSAMPLE,\n",
    "    out_stride=TARGET_STRIDE\n",
    ").to(device)\n",
    "\n",
    "# EMA 评估器\n",
    "ema = EMA(model_fpn)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 加载数据\n",
    "\n",
    "# %%\n",
    "# 训练数据加载器（建议此处按需开启轻度增强）\n",
    "train_aug_config = {\"use_flip\": False, \"use_color_aug\": False}\n",
    "train_loader = create_kpts_dataloader(\n",
    "    dataset_root=COCO_ROOT,\n",
    "    img_size=INPUT_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    target_stride=TARGET_STRIDE,\n",
    "    pin_memory=True,\n",
    "    aug_cfg=train_aug_config,\n",
    "    is_train=True\n",
    ")\n",
    "\n",
    "# 验证：严格关闭随机增强，确保曲线稳定\n",
    "test_aug_config = {\"use_flip\": False, \"use_color_aug\": False}\n",
    "val_loader = create_kpts_dataloader(\n",
    "    dataset_root=COCO_ROOT,\n",
    "    img_size=INPUT_SIZE,\n",
    "    batch_size=BATCH_SIZE * 2,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    target_stride=TARGET_STRIDE,\n",
    "    pin_memory=True,\n",
    "    aug_cfg=test_aug_config,\n",
    "    is_train=False\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 损失/优化/调度\n",
    "\n",
    "# %%\n",
    "# ★ 损失函数：开启骨架一致性（bg 先关）\n",
    "criterion = MoveNetLoss(\n",
    "    hm_weight=1.0, ct_weight=1.0, reg_weight=1.5, off_weight=1.0,\n",
    "    bone_weight=0.15,   # 建议 0.10~0.20 之间微调\n",
    "    bg_weight=0.0\n",
    ")\n",
    "\n",
    "# ★ 优化器：推荐 AdamW 更稳（如需用 Adam，把下面一行改回 torch.optim.Adam）\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model_fpn.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "# 学习率调度器（余弦退火）\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 加载预训练/断点\n",
    "\n",
    "# %%\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True)\n",
    "\n",
    "last_pt_path = os.path.join(WEIGHTS_DIR, \"last.pt\")\n",
    "if os.path.exists(last_pt_path):\n",
    "    print(\"--- Resuming training from last.pt ---\")\n",
    "    checkpoint = torch.load(last_pt_path, map_location=device)\n",
    "\n",
    "    model_fpn.load_state_dict(checkpoint['model'])\n",
    "    ema.ema_model.load_state_dict(checkpoint['ema_model'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "\n",
    "    START_EPOCH = checkpoint['epoch'] + 1\n",
    "    BEST_VAL_LOSS = checkpoint['best_val_loss']\n",
    "\n",
    "    print(f\"Resumed from epoch {START_EPOCH-1}. Best validation loss so far: {BEST_VAL_LOSS:.4f}\")\n",
    "    print(f\"Current learning rate is {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 训练循环\n",
    "\n",
    "# %%\n",
    "print(\"\\n--- Starting Training ---\")\n",
    "\n",
    "# 预热步数\n",
    "warmup_steps = WARMUP_EPOCHS * len(train_loader)\n",
    "current_step = START_EPOCH * len(train_loader)\n",
    "\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "    model_fpn.train()\n",
    "\n",
    "    # 统计项\n",
    "    epoch_loss_heatmap = 0.0\n",
    "    epoch_loss_center  = 0.0\n",
    "    epoch_loss_regs    = 0.0\n",
    "    epoch_loss_offsets = 0.0\n",
    "    epoch_loss_bone    = 0.0\n",
    "    epoch_loss_bg      = 0.0\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    pbar = tqdm(train_loader, desc=f\"  🟢 [Training] lr: {optimizer.param_groups[0]['lr']:.6f} \")\n",
    "\n",
    "    for i, (imgs, labels, kps_masks, _) in enumerate(pbar):\n",
    "        # 线性预热\n",
    "        if current_step < warmup_steps:\n",
    "            lr_scale = (current_step + 1) / max(1, warmup_steps)\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] = LEARNING_RATE * lr_scale\n",
    "\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        kps_masks = kps_masks.to(device, non_blocking=True)\n",
    "\n",
    "        # 前向\n",
    "        preds = model_fpn(imgs)\n",
    "        total_loss, loss_dict = criterion(preds, labels, kps_masks)\n",
    "\n",
    "        # 反传\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        total_loss.backward()\n",
    "\n",
    "        # 梯度裁剪\n",
    "        torch.nn.utils.clip_grad_norm_(model_fpn.parameters(), max_norm=GRADIENT_CLIP_VAL)\n",
    "\n",
    "        # 更新\n",
    "        optimizer.step()\n",
    "        ema.update(model_fpn)\n",
    "        current_step += 1\n",
    "\n",
    "        # 累计显示\n",
    "        epoch_loss_heatmap += float(loss_dict[\"loss_heatmap\"])\n",
    "        epoch_loss_center  += float(loss_dict[\"loss_center\"])\n",
    "        epoch_loss_regs    += float(loss_dict[\"loss_regs\"])\n",
    "        epoch_loss_offsets += float(loss_dict[\"loss_offsets\"])\n",
    "        if criterion.bone_weight > 0:\n",
    "            epoch_loss_bone  += float(loss_dict[\"loss_bone\"])\n",
    "        if criterion.bg_weight > 0:\n",
    "            epoch_loss_bg    += float(loss_dict[\"loss_bg\"])\n",
    "\n",
    "        pbar.set_postfix(\n",
    "            hm=f\"{epoch_loss_heatmap:.2f}\",\n",
    "            center=f\"{epoch_loss_center:.2f}\",\n",
    "            regs=f\"{epoch_loss_regs:.2f}\",\n",
    "            offsets=f\"{epoch_loss_offsets:.2f}\",\n",
    "            bone=(f\"{epoch_loss_bone:.2f}\" if criterion.bone_weight > 0 else \"0.00\"),\n",
    "            bg=(f\"{epoch_loss_bg:.2f}\" if criterion.bg_weight > 0 else \"0.00\"),\n",
    "        )\n",
    "\n",
    "    # 调度器步进（放在一个 epoch 结束后）\n",
    "    if epoch >= WARMUP_EPOCHS - 1:\n",
    "        scheduler.step()\n",
    "\n",
    "    # ===== 验证（用 EMA 模型）=====\n",
    "    avg_total_loss, avg_dict = evaluate_local(\n",
    "        ema.ema_model, val_loader, criterion, device,\n",
    "        decoder=decode_movenet_outputs, stride=TARGET_STRIDE\n",
    "    )\n",
    "    print(f\"  📜 Epoch {epoch+1}/{EPOCHS} average loss: {avg_total_loss:.4f}\")\n",
    "\n",
    "    # ===== 保存权重 =====\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model': model_fpn.state_dict(),\n",
    "        'ema_model': ema.ema_model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'scheduler': scheduler.state_dict(),\n",
    "        'best_val_loss': BEST_VAL_LOSS,\n",
    "    }\n",
    "    torch.save(checkpoint, last_pt_path)\n",
    "    print(f\"  🎯 Saved last checkpoint to {last_pt_path}\")\n",
    "\n",
    "    if avg_total_loss < BEST_VAL_LOSS:\n",
    "        BEST_VAL_LOSS = avg_total_loss\n",
    "        checkpoint['best_val_loss'] = BEST_VAL_LOSS\n",
    "        best_pt_path = os.path.join(WEIGHTS_DIR, \"best.pt\")\n",
    "        torch.save(checkpoint, best_pt_path)\n",
    "        print(f\"  🎉 New best model found! Saved to {best_pt_path}\")\n",
    "\n",
    "    # ===== 每 5 个 epoch 可视化（用 EMA 模型；只画关键点+骨架）=====\n",
    "    # if (epoch + 1) % 1 == 0:\n",
    "    if True:\n",
    "        print(f\"  📊 Visualizing predictions on test image...\")\n",
    "        viz_dir = os.path.join(WEIGHTS_DIR, \"viz\")\n",
    "        os.makedirs(viz_dir, exist_ok=True)\n",
    "        save_path = os.path.join(viz_dir, f\"epoch_{epoch+1:03d}.png\")\n",
    "\n",
    "        # 1. 加载并预处理图像 (与visualizer.py示例中的逻辑相同)\n",
    "        image_bgr = cv2.imread(TEST_IMAGE_PATH)\n",
    "        if image_bgr is None:\n",
    "            print(f\"Warning: Test image not found at {TEST_IMAGE_PATH}, skipping visualization.\")\n",
    "        else:\n",
    "            image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Letterbox + 归一化\n",
    "            h, w, _ = image_rgb.shape\n",
    "            scale = INPUT_SIZE / max(h, w)\n",
    "            new_w, new_h = int(w * scale), int(h * scale)\n",
    "            resized_img = cv2.resize(image_rgb, (new_w, new_h))\n",
    "\n",
    "            padded_img = np.zeros((INPUT_SIZE, INPUT_SIZE, 3), dtype=np.uint8)\n",
    "            top, left = (INPUT_SIZE - new_h) // 2, (INPUT_SIZE - new_w) // 2\n",
    "            padded_img[top:top+new_h, left:left+new_w] = resized_img\n",
    "\n",
    "            transform = A.Compose([\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "            input_tensor = transform(image=padded_img)['image'].unsqueeze(0).to(device)\n",
    "\n",
    "            # 2. 模型推理 (使用EMA模型)\n",
    "            preds = ema.ema_model(input_tensor)\n",
    "\n",
    "            # 3. 解码\n",
    "            detections = decode_movenet_outputs(\n",
    "                preds, \n",
    "                img_size=(h, w),\n",
    "                stride=TARGET_STRIDE,\n",
    "                keypoint_thresh=0.1 # 可根据需要调整\n",
    "            )\n",
    "            print(detections)\n",
    "\n",
    "            # 4. 调用新的可视化函数\n",
    "            viz_image = visualize_detections(\n",
    "                image=image_rgb,\n",
    "                detections=detections,\n",
    "                heatmaps=preds['heatmaps'][0],\n",
    "                keypoint_thresh=0.1\n",
    "            )\n",
    "\n",
    "            # 5. 保存结果 (使用OpenCV保存，避免matplotlib的白边)\n",
    "            # 将RGB转回BGR以便OpenCV保存\n",
    "            viz_image_bgr = cv2.cvtColor(viz_image, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imwrite(save_path, viz_image_bgr)\n",
    "            print(f\"  -> Visualization saved to {save_path}\")\n",
    "\n",
    "print(\"--- Training Finished ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparrow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
