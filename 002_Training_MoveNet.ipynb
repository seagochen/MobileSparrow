{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c77219de",
   "metadata": {},
   "source": [
    "# MoveNet_FPN 训练笔记"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c3c530",
   "metadata": {},
   "source": [
    "## 导入工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ccc7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cxt/miniconda3/envs/sparrow/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 导入系统库\n",
    "import os\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 导入sparrow\n",
    "from sparrow.models.movenet_fpn import MoveNet_FPN, decode_movenet_outputs\n",
    "from sparrow.datasets.coco_kpts import create_kpts_dataloader\n",
    "from sparrow.losses.movenet_loss import MoveNetLoss, evaluate\n",
    "from sparrow.utils.ema import EMA\n",
    "from sparrow.utils.visual_movenet import visualize_movenet\n",
    "\n",
    "# 导入torch库\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0c5166",
   "metadata": {},
   "source": [
    "## 参数设置\n",
    "\n",
    "### 系统参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf2164b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "INPUT_SIZE = 192\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 4\n",
    "NUM_JOINTS = 17\n",
    "UPSAMPLE = False\n",
    "\n",
    "COCO_ROOT = \"./data/coco2017_movenet\"       # COCO训练数据集\n",
    "WEIGHTS_DIR = \"./outputs/movenet\"           # 保存权重的目录\n",
    "TEST_IMAGE_PATH = \"./res/girl_with_bags.png\"    # 测试图片路径"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c152cc",
   "metadata": {},
   "source": [
    "### 学习参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "426df7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_EPOCH = 0\n",
    "EPOCHS=100                      # 训练次数\n",
    "BEST_VAL_LOSS = float('inf')\n",
    "LEARNING_RATE = 1e-4            # 初始学习率\n",
    "WEIGHT_DECAY = 1e-3\n",
    "WARMUP_EPOCHS = 2               # 预热\n",
    "GRADIENT_CLIP_VAL = 5.0         # 梯度裁剪的阈值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea85236",
   "metadata": {},
   "source": [
    "## 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f565b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (classifier.bias, classifier.weight, conv_head.bias, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    }
   ],
   "source": [
    "backbone_fpn = timm.create_model('mobilenetv3_large_100', pretrained=True, features_only=True, out_indices=(2, 3, 4))\n",
    "model_fpn = MoveNet_FPN(backbone_fpn, num_joints=NUM_JOINTS, fpn_out_channels=128, upsample_to_quarter=False)\n",
    "model_fpn.to(device)\n",
    "\n",
    "# EMA评估器\n",
    "ema = EMA(model_fpn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ffb45d",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76ebda0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cxt/projects/MobileSparrow/sparrow/datasets/coco_kpts.py:128: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  transforms.append(A.PadIfNeeded(\n",
      "/home/cxt/miniconda3/envs/sparrow/lib/python3.10/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/home/cxt/projects/MobileSparrow/sparrow/datasets/coco_kpts.py:141: UserWarning: Argument(s) 'value' are not valid for transform ShiftScaleRotate\n",
      "  transforms.append(A.ShiftScaleRotate(\n"
     ]
    }
   ],
   "source": [
    "# 创建训练数据加载器 (来自 dataloader.py)\n",
    "train_aug_config = { \"use_flip\": True, \"use_color_aug\": True }\n",
    "train_loader = create_kpts_dataloader(\n",
    "    dataset_root=COCO_ROOT,\n",
    "    img_size=INPUT_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    target_stride=8,\n",
    "    pin_memory=True,\n",
    "    aug_cfg=train_aug_config,\n",
    "    is_train=True\n",
    ")\n",
    "\n",
    "# 创建验证集数据加载器\n",
    "test_aug_config = {\"use_flip\": True}\n",
    "val_loader = create_kpts_dataloader(\n",
    "    dataset_root=COCO_ROOT,\n",
    "    img_size=INPUT_SIZE,\n",
    "    batch_size=BATCH_SIZE * 2,  # 验证时通常可以用更大的 batch size\n",
    "    num_workers=NUM_WORKERS,\n",
    "    target_stride=8,\n",
    "    pin_memory=True,\n",
    "    aug_cfg=test_aug_config,\n",
    "    is_train=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb7fda2",
   "metadata": {},
   "source": [
    "## 损失优化调度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec2f4e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "criterion = MoveNetLoss(reg_weight=2.0, off_weight=1.0)\n",
    "\n",
    "# 优化器\n",
    "optimizer = torch.optim.AdamW(model_fpn.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# 学习调度器\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7b845f",
   "metadata": {},
   "source": [
    "## 加载预训练权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd5743c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保存放预训练的目录存在\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True) # 确保目录存在\n",
    "\n",
    "# 断点续训逻辑\n",
    "last_pt_path = os.path.join(WEIGHTS_DIR, \"last.pt\")\n",
    "if os.path.exists(last_pt_path):\n",
    "    print(\"--- Resuming training from last.pt ---\")\n",
    "\n",
    "    # 加载pt文件\n",
    "    checkpoint = torch.load(last_pt_path, map_location=device)\n",
    "    \n",
    "    # 从pt中读取模型权重\n",
    "    model_fpn.load_state_dict(checkpoint['model'])\n",
    "    \n",
    "    # 加载EMA状态\n",
    "    ema.ema_model.load_state_dict(checkpoint['ema_model'])\n",
    "\n",
    "    # 加载优化器状态\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "    # 加载调度器状态\n",
    "    scheduler.load_state_dict(checkpoint['scheduler'])\n",
    "\n",
    "    # 更新EPOCH状态\n",
    "    START_EPOCH = checkpoint['epoch'] + 1\n",
    "    \n",
    "    # 更新最佳损失状态\n",
    "    BEST_VAL_LOSS = checkpoint['best_val_loss']\n",
    "    \n",
    "    # 打印确认消息\n",
    "    print(f\"Resumed from epoch {START_EPOCH-1}. Best validation loss so far: {BEST_VAL_LOSS:.4f}\")\n",
    "    print(f\"Current learning rate is {optimizer.param_groups[0]['lr']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353631e5",
   "metadata": {},
   "source": [
    "## 训练循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a64177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Training ---\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  🟢 [Training] lr: 0.000100 :   9%|▊         | 1381/16220 [00:24<04:19, 57.23it/s, center=23.1880, hm=39.3803, offsets=1727.3296, regs=3538.1776]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# 反向传播和优化\u001b[39;00m\n\u001b[1;32m     41\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 42\u001b[0m \u001b[43mtotal_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# 梯度裁剪\u001b[39;00m\n\u001b[1;32m     45\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model_fpn\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39mGRADIENT_CLIP_VAL)\n",
      "File \u001b[0;32m~/miniconda3/envs/sparrow/lib/python3.10/site-packages/torch/_tensor.py:647\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    639\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    640\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    645\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    646\u001b[0m     )\n\u001b[0;32m--> 647\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sparrow/lib/python3.10/site-packages/torch/autograd/__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sparrow/lib/python3.10/site-packages/torch/autograd/graph.py:829\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    827\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    833\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- 训练循环 ---\n",
    "print(\"\\n--- Starting Training ---\")\n",
    "\n",
    "# 计算预热的总步数\n",
    "warmup_steps = WARMUP_EPOCHS * len(train_loader)\n",
    "current_step = START_EPOCH * len(train_loader)\n",
    "\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "    model_fpn.train() # 设置为训练模式\n",
    "\n",
    "    epoch_loss_heatmap = 0.0\n",
    "    epoch_loss_center = 0.0\n",
    "    epoch_loss_regs = 0.0\n",
    "    epoch_loss_offsets = 0.0\n",
    "\n",
    "    # 进度条信息\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    pbar = tqdm(train_loader, desc=f\"  🟢 [Training] lr: {optimizer.param_groups[0]['lr']:.6f} \")\n",
    "\n",
    "    for i, (imgs, labels, kps_masks, _) in enumerate(pbar):\n",
    "    \n",
    "        # 学习率预热逻辑\n",
    "        if current_step < warmup_steps:\n",
    "            # 线性预热\n",
    "            lr_scale = (current_step + 1) / warmup_steps\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = LEARNING_RATE * lr_scale\n",
    "        \n",
    "        # 正常训练步骤\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        kps_masks = kps_masks.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        preds = model_fpn(imgs)\n",
    "\n",
    "        # 计算损失\n",
    "        total_loss, loss_dict = criterion(preds, labels, kps_masks) \n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "\n",
    "        # 梯度裁剪\n",
    "        torch.nn.utils.clip_grad_norm_(model_fpn.parameters(), max_norm=GRADIENT_CLIP_VAL)\n",
    "        \n",
    "        # 更新模型参数\n",
    "        optimizer.step()\n",
    "\n",
    "        # 更新EMA\n",
    "        ema.update(model_fpn)\n",
    "        current_step += 1\n",
    "\n",
    "        epoch_loss_center += loss_dict[\"loss_center\"]\n",
    "        epoch_loss_heatmap += loss_dict[\"loss_heatmap\"]\n",
    "        epoch_loss_offsets += loss_dict[\"loss_offsets\"]\n",
    "        epoch_loss_regs += loss_dict[\"loss_regs\"]\n",
    "\n",
    "        # 显示当前信息\n",
    "        pbar.set_postfix(hm=f\"{epoch_loss_heatmap:.2f}\", \n",
    "                         center=f\"{epoch_loss_center:.2f}\", \n",
    "                         offsets=f\"{epoch_loss_offsets:.2f}\",\n",
    "                         regs=f\"{epoch_loss_regs:.2f}\")\n",
    "    # end-for: 训练结束\n",
    "\n",
    "    # 每个 epoch 结束后，更新学习率调度器\n",
    "    if epoch >= WARMUP_EPOCHS - 1: # -1 是因为 step() 应在 optimizer.step() 之后调用\n",
    "        scheduler.step()\n",
    "\n",
    "    # 每个 epoch 结束后，进行验证\n",
    "    avg_total_loss, _, = evaluate(ema.ema_model, val_loader, criterion, device, decoder=decode_movenet_outputs)\n",
    "\n",
    "    # 生成本次epoch报告\n",
    "    print(f\"  📜 Epoch {epoch+1}/{EPOCHS} average loss: {avg_total_loss:.4f}\")\n",
    "\n",
    "    # 保存 last.pt 和 best.pt\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model': model_fpn.state_dict(),\n",
    "        'ema_model': ema.ema_model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'scheduler': scheduler.state_dict(),\n",
    "        'best_val_loss': BEST_VAL_LOSS,\n",
    "    }\n",
    "\n",
    "    # 保存 last.pt\n",
    "    torch.save(checkpoint, last_pt_path)\n",
    "    print(f\"  🎯 Saved last checkpoint to {last_pt_path}\")\n",
    "    \n",
    "    # 如果当前是最佳模型，则保存 best.pt\n",
    "    if avg_total_loss < BEST_VAL_LOSS:\n",
    "        BEST_VAL_LOSS = avg_total_loss\n",
    "        checkpoint['best_val_loss'] = BEST_VAL_LOSS # 更新 checkpoint 中的最佳损失\n",
    "        best_pt_path = os.path.join(WEIGHTS_DIR, \"best.pt\")\n",
    "        torch.save(checkpoint, best_pt_path)\n",
    "        print(f\"  🎉 New best model found! Saved to {best_pt_path}\")\n",
    "        \n",
    "    # --- 每 5 个 epoch，可视化一次预测结果 ---\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"  📊 Visualized predictions on test image\")\n",
    "        viz_dir = os.path.join(WEIGHTS_DIR, \"viz\")\n",
    "        os.makedirs(viz_dir, exist_ok=True)\n",
    "\n",
    "        # 1) 加载图片\n",
    "        import cv2\n",
    "        img_bgr = cv2.imread(TEST_IMAGE_PATH)\n",
    "        if img_bgr is None:\n",
    "            raise FileNotFoundError(f\"TEST_IMAGE_PATH not found: {TEST_IMAGE_PATH}\")\n",
    "        \n",
    "        # 非等比例直接拉伸\n",
    "        img_resized = cv2.resize(img_bgr, (600, 600), interpolation=cv2.INTER_LINEAR)  \n",
    "\n",
    "        # 2) 可视化保存叠框结果（会回到这张 800x600 的坐标系上绘制）\n",
    "        save_path = os.path.join(viz_dir, f\"epoch_{epoch+1:03d}.png\")\n",
    "        visualize_movenet(\n",
    "            model=model_fpn,\n",
    "            image=img_resized,               # 或者传入 np.ndarray(BGR/RGB 都行，这里内部按 RGB 处理显示)\n",
    "            device=device,\n",
    "            decoder=decode_movenet_outputs, # 直接用你已有的解码器\n",
    "            input_size=192,\n",
    "            stride=8,                       # 若模型把 P3 上采样到1/4，这里改成 4\n",
    "            topk_centers=5,\n",
    "            center_thresh=0.25,\n",
    "            keypoint_thresh=0.05,\n",
    "            draw_bbox=True,\n",
    "            draw_skeleton=True,\n",
    "            draw_on_orig=True,              # 画在原图上\n",
    "            draw_heatmaps=True,\n",
    "            save_path=save_path,    # 或 None 并 show=True 直接显示\n",
    "            show=False\n",
    "        )\n",
    "            \n",
    "print(\"--- Training Finished ---\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparrow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
