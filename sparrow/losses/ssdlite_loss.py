# %% [markdown]
# # æŸå¤±å‡½æ•°
# 
# å¥½çš„ï¼Œæˆ‘ä»¬å·²ç»å‡†å¤‡å¥½äº†ç°ä»£åŒ–çš„ `SSDLite_FPN` æ¨¡å‹å’Œå¼ºå¤§çš„ `Albumentations` æ•°æ®åŠ è½½å™¨ã€‚ç°åœ¨ï¼Œæœ€åä¸€å—æ‹¼å›¾å°±æ˜¯ä¸ºè¿™ä¸ªç›®æ ‡æ£€æµ‹æ¨¡å‹è®¾è®¡å’Œå®ç°ä¸€ä¸ªåˆé€‚çš„æŸå¤±å‡½æ•° (Loss Function)ã€‚
# 
# å¯¹äºåƒ SSDã€RetinaNet æˆ–æˆ‘ä»¬è¿™ä¸ª `SSDLite_FPN` è¿™æ ·çš„å•é˜¶æ®µï¼ˆOne-Stageï¼‰æ£€æµ‹å™¨ï¼ŒæŸå¤±å‡½æ•°é€šå¸¸ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼š
# 
# 1.  **åˆ†ç±»æŸå¤± (Classification Loss)**ï¼šæƒ©ç½šé¢„æµ‹æ¡†çš„ç±»åˆ«é”™è¯¯ã€‚
# 2.  **å®šä½æŸå¤± (Localization/Regression Loss)**ï¼šæƒ©ç½šé¢„æµ‹æ¡†ä¸çœŸå®æ¡†ï¼ˆGround Truthï¼‰ä¹‹é—´çš„ä½ç½®åå·®ã€‚
# 
# æ€»æŸå¤±æ˜¯è¿™ä¸¤éƒ¨åˆ†æŸå¤±çš„åŠ æƒå’Œï¼š$L\_{total} = L\_{cls} + \\alpha L\_{loc}$ ï¼ˆæƒé‡ $\\alpha$ é€šå¸¸è®¾ä¸º1ï¼‰ã€‚
# 
# åœ¨è®¡ç®—è¿™ä¸¤ä¸ªæŸå¤±ä¹‹å‰ï¼Œæœ€å…³é”®çš„ä¸€æ­¥æ˜¯**ç›®æ ‡åˆ†é…ï¼ˆTarget Assignmentï¼‰**ï¼Œä¹Ÿå°±æ˜¯ä¸ºæ¨¡å‹ç”Ÿæˆçš„æˆåƒä¸Šä¸‡ä¸ªé”šæ¡†ï¼ˆAnchor Boxesï¼‰ä¸­çš„æ¯ä¸€ä¸ªï¼Œåˆ†é…ä¸€ä¸ªçœŸå®çš„æ ‡ç­¾ï¼ˆæ˜¯èƒŒæ™¯ï¼Œè¿˜æ˜¯æŸä¸ªç‰©ä½“ï¼Ÿå¦‚æœæ˜¯ç‰©ä½“ï¼Œå¯¹åº”çš„çœŸå®æ¡†æ˜¯å“ªä¸€ä¸ªï¼Ÿï¼‰ã€‚
# 
# ä¸‹é¢ï¼Œæˆ‘å°†ä¸ºä½ åˆ†æ­¥å®ç°ä¸€ä¸ªå®Œæ•´çš„ã€é€‚ç”¨äº `SSDLite_FPN` çš„æŸå¤±å‡½æ•°æ¨¡å—ã€‚
# 
# -----

# %% [markdown]
# ## æ ¸å¿ƒæ­¥éª¤
# 
# æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ª `SSDLoss` ç±»ï¼Œå…¶æ ¸å¿ƒé€»è¾‘åˆ†ä¸ºä¸‰æ­¥ï¼š
# 
# 1.  **ç”Ÿæˆé”šæ¡† (Anchor Generation)**ï¼šä¸ºæ¨¡å‹è¾“å‡ºçš„æ¯ä¸ªå°ºå¯¸çš„ç‰¹å¾å›¾ï¼ˆP3, P4, P5, P6, P7ï¼‰é¢„å…ˆç”Ÿæˆä¸€ç»„å›ºå®šçš„é”šæ¡†ã€‚è¿™ä¸€æ­¥åœ¨åˆå§‹åŒ–æ—¶å®Œæˆã€‚
# 2.  **ç›®æ ‡åˆ†é… (Target Assignment)**ï¼šåœ¨æ¯æ¬¡è®­ç»ƒè¿­ä»£ä¸­ï¼Œæ ¹æ®çœŸå®æ¡†ï¼ˆGround Truth Boxesï¼‰å’Œæ‰€æœ‰é”šæ¡†çš„ IoUï¼ˆäº¤å¹¶æ¯”ï¼‰ï¼Œä¸ºæ¯ä¸ªé”šæ¡†åˆ†é…åŒ¹é…çš„çœŸå®ç‰©ä½“æˆ–å°†å…¶æ ‡è®°ä¸ºèƒŒæ™¯ã€‚
# 3.  **è®¡ç®—æŸå¤± (Loss Calculation)**ï¼š
#       * **åˆ†ç±»æŸå¤±**ï¼šä½¿ç”¨ **Focal Loss**ã€‚è¿™æ˜¯ç°ä»£æ£€æµ‹å™¨ä¸­éå¸¸æµè¡Œä¸”æœ‰æ•ˆçš„æŸå¤±å‡½æ•°ï¼Œå®ƒèƒ½è‡ªåŠ¨å…³æ³¨äºéš¾åˆ†ç±»çš„æ ·æœ¬ï¼ˆhard examplesï¼‰ï¼Œè§£å†³äº†æ­£è´Ÿæ ·æœ¬ï¼ˆç‰©ä½“ vs. èƒŒæ™¯ï¼‰æåº¦ä¸å¹³è¡¡çš„é—®é¢˜ã€‚
#       * **å®šä½æŸå¤±**ï¼šä½¿ç”¨ **Smooth L1 Loss**ã€‚è¿™æ˜¯ä¸€ç§å¯¹ç¦»ç¾¤å€¼ä¸é‚£ä¹ˆæ•æ„Ÿçš„å›å½’æŸå¤±ï¼Œæ¯” L2 Loss æ›´é²æ£’ã€‚æˆ‘ä»¬åªå¯¹è¢«åˆ†é…ä¸ºæ­£æ ·æœ¬ï¼ˆåŒ¹é…åˆ°ç‰©ä½“ï¼‰çš„é”šæ¡†è®¡ç®—å®šä½æŸå¤±ã€‚
# 
# -----

# %% [markdown]
# ### ç¬¬ä¸€æ­¥ï¼šå®‰è£…ä¾èµ–
# 
# æˆ‘ä»¬éœ€è¦ `torchvision` æ¥æ–¹ä¾¿åœ°è®¡ç®— IoU å’ŒæŸå¤±ã€‚åŒæ—¶ä½¿ç”¨ `tqdm` æ¥æ˜¾ç¤ºè®­ç»ƒè¿›åº¦å’Œé”™è¯¯ç‡ã€‚

# %%
# !pip -q install torchvision
# !pip -q install tqdm

# %% [markdown]
# ### ç¬¬äºŒæ­¥ï¼šé”šæ¡†ç”Ÿæˆå™¨ (Anchor Generator)
# 
# æˆ‘ä»¬éœ€è¦ä¸€ä¸ªè¾…åŠ©ç±»æ¥ä¸ºä¸åŒå°ºå¯¸çš„ç‰¹å¾å›¾ç”Ÿæˆé”šæ¡†ã€‚

# %%
import torch
import math
from typing import List, Sequence, Union

class AnchorGenerator:
    """
    ä¸ºé‡‘å­—å¡”ç‰¹å¾(FPN)çš„å¤šä¸ªç‰¹å¾å›¾ç”Ÿæˆé”šæ¡†(anchor)çš„å·¥å…·ç±»ã€‚

    è®¾è®¡ç›®æ ‡
    ----------
    - åœ¨è®­ç»ƒå¼€å§‹å‰â€œé¢„è®¡ç®—â€æ¯ä¸ªå±‚çº§(å°ºåº¦)çš„ä¸€ç»„**åŸºç¡€å•å…ƒé”šæ¡†**(cell anchors)ï¼Œ
      åç»­åœ¨ç½‘æ ¼ä¸Šå¹³ç§»å¤åˆ¶ä»¥å¾—åˆ°æ•´å¼ å›¾åƒä¸Šçš„é”šæ¡†é›†åˆã€‚
    - æ”¯æŒå¤šå°ºåº¦(sizes)å’Œå¤šé•¿å®½æ¯”(aspect_ratios)ï¼Œå¯ä¸å¸¸è§çš„ä¸¤é˜¶æ®µ/å•é˜¶æ®µæ£€æµ‹å™¨å¯¹é½ã€‚

    åæ ‡/å½¢çŠ¶çº¦å®š
    ----------
    - æ¡†åæ ‡æ ¼å¼ï¼š
        - `cx, cy, w, h`ï¼šä¸­å¿ƒç‚¹ä¸å®½é«˜ï¼Œå•ä½=åƒç´ ï¼Œ`cx, cy`ä½äºå·¦ä¸Šè§’ä¸º(0,0)çš„å›¾åƒåæ ‡ç³»ã€‚
        - `x1, y1, x2, y2`ï¼šå·¦ä¸Šä¸å³ä¸‹è§’ï¼Œå•ä½=åƒç´ ï¼Œæ»¡è¶³ `x2 > x1` ä¸” `y2 > y1`ã€‚
    - `cell_anchors[i]` çš„å½¢çŠ¶ä¸º `[A, 4]`ï¼ŒA = `len(aspect_ratios)`ã€‚
      è¿™æ˜¯ä¸€ç»„ä»¥(0,0)ä¸ºä¸­å¿ƒçš„â€œåŸç‚¹é”šæ¡†â€ï¼Œåç»­é€šè¿‡å¹³ç§»æ”¾ç½®åˆ°ç‰¹å¾å›¾å„ç½‘æ ¼ä¸­å¿ƒã€‚
    - `generate_anchors_on_grid(...)` è¿”å›å½¢çŠ¶ `[N_total, 4]` çš„å¼ é‡ï¼ˆ`xyxy` æ ¼å¼ï¼‰ï¼Œ
      å…¶ä¸­ `N_total = sum_i (H_i * W_i * A)`ï¼Œiæ˜¯é‡‘å­—å¡”å±‚çº§ï¼ŒH_i/W_iä¸ºè¯¥å±‚ç‰¹å¾å›¾é«˜å®½ã€‚

    å…³é”®å‡è®¾
    ----------
    - è¾“å…¥å›¾åƒå°ºå¯¸åœ¨å½“å‰å®ç°ä¸­å›ºå®šä¸º 320x320ï¼ˆè§ `generate_anchors_on_grid` å†…éƒ¨å¸¸é‡ï¼‰ã€‚
      è‹¥ä½ çš„è®­ç»ƒ/æ¨ç†è¾“å…¥å°ºå¯¸å¯å˜ï¼Œè¯·å°†å…¶æ”¹ä¸ºåŠ¨æ€ä¼ å…¥ï¼Œæˆ–è€…æ ¹æ®å®é™… pipeline æ›¿æ¢è¿™é‡Œçš„å¸¸é‡ã€‚
    - æ¯ä¸ªå±‚çº§ i çš„åŸºç¡€å°ºå¯¸ `sizes[i]` ä¸è¯¥å±‚çš„ stride å¯¹åº”å…³ç³»éœ€ç”±è°ƒç”¨æ–¹ä¿è¯â€œåˆç†â€ï¼Œ
      å¦åˆ™é”šæ¡†çš„æ„Ÿå—é‡ä¸ç‰¹å¾å±‚ä¸åŒ¹é…ä¼šå½±å“æ€§èƒ½ï¼ˆå¸¸è§åšæ³•æ˜¯ `sizes ~ base * 2**i`ï¼‰ã€‚

    å¤æ‚åº¦
    ----------
    - é¢„è®¡ç®— `cell_anchors`ï¼šO(#levels * #ratios) â€”â€” ä¸€æ¬¡æ€§ã€‚
    - å…¨å›¾é”šæ¡†ç”Ÿæˆï¼šO( sum_i (H_i * W_i * #ratios) ) â€”â€” ä¸ç‰¹å¾å›¾ç½‘æ ¼æ•°æˆæ­£æ¯”ã€‚

    ç”¨æ³•ç¤ºä¾‹
    ----------
    >>> ag = AnchorGenerator(
    ...     sizes=(32, 64, 128, 256, 512),
    ...     aspect_ratios=(0.5, 1.0, 2.0, 1/3.0, 3.0)
    ... )
    >>> # å‡è®¾æ¥è‡ª FPN çš„ä¸‰ä¸ªå±‚çº§ç‰¹å¾å›¾ (N, C, H, W) â€”â€” è¿™é‡Œåªç”¨å®ƒä»¬çš„ç©ºé—´å°ºå¯¸
    >>> fms = [torch.empty(1, 256, 80, 80), torch.empty(1, 256, 40, 40), torch.empty(1, 256, 20, 20)]
    >>> anchors = ag.generate_anchors_on_grid([fm for fm in fms], device="cpu")
    >>> anchors.shape  # [ (80*80+40*40+20*20) * len(aspect_ratios), 4 ]
    torch.Size([ ( ... ), 4 ])

    å‚æ•°
    ----------
    sizes : Sequence[int|float]
        æ¯ä¸ªå±‚çº§(ä¸FPNè¾“å‡ºä¸€ä¸€å¯¹åº”)çš„â€œåŸºç¡€å°ºå¯¸â€ï¼Œç†è§£ä¸ºè¯¥å±‚é”šæ¡†çš„å‚è€ƒè¾¹é•¿(åƒç´ )ã€‚
        è¿™ä¸æ˜¯ w æˆ– hï¼Œè€Œæ˜¯åœ¨ç”Ÿæˆä¸åŒé•¿å®½æ¯”æ—¶æ´¾ç”Ÿ w/h çš„æ ‡å°ºã€‚
    aspect_ratios : Sequence[float]
        æ¯ä¸ªä½ç½®ç”Ÿæˆå¤šå°‘ç§é•¿å®½æ¯”çš„é”šæ¡†ï¼Œå€¼ä¸º w/hï¼ˆä¾‹å¦‚ 0.5=ç«–é•¿ï¼Œ1.0=æ­£æ–¹ï¼Œ2.0=æ¨ªé•¿ï¼‰ã€‚

    å±æ€§
    ----------
    num_anchors_per_location : int
        æ¯ä¸ªä½ç½®(ç½‘æ ¼ç‚¹)ç”Ÿæˆçš„é”šæ¡†æ•°é‡ï¼Œç­‰äº len(aspect_ratios)ã€‚
    cell_anchors : List[Tensor]
        é¢„ç”Ÿæˆçš„â€œåŸç‚¹â€åŸºç¡€é”šæ¡†åˆ—è¡¨ï¼›é•¿åº¦ç­‰äº len(sizes)ï¼Œæ¯ä¸ªå…ƒç´ å½¢å¦‚ [A, 4] (xyxy)ã€‚
    """

    def __init__(self,
                 sizes: Sequence[Union[int, float]] = (32, 64, 128, 256, 512),
                 aspect_ratios: Sequence[float] = (0.5, 1.0, 2.0, 1/3.0, 3.0)):
        super().__init__()
        self.sizes = sizes
        self.aspect_ratios = aspect_ratios
        self.num_anchors_per_location = len(self.aspect_ratios)
        # é¢„è®¡ç®—ï¼šæ¯ä¸ªå±‚çº§çš„ä¸€ç»„â€œä»¥åŸç‚¹ä¸ºä¸­å¿ƒâ€çš„åŸºç¡€é”šæ¡†ï¼ˆxyxyï¼Œå•ä½åƒç´ ï¼‰
        self.cell_anchors = self._generate_cell_anchors()

    def _generate_cell_anchors(self) -> List[torch.Tensor]:
        """
        ä¸ºæ¯ä¸ªå°ºåº¦ç”Ÿæˆä»¥(0,0)ä¸ºä¸­å¿ƒçš„ä¸€ç»„åŸºç¡€é”šæ¡†ï¼ˆä¸å«å¹³ç§»ï¼‰ï¼Œå¹¶å­˜ä¸º xyxy æ ¼å¼ã€‚

        ç”Ÿæˆè§„åˆ™
        ----------
        å¯¹äºç»™å®šå°ºåº¦ s å’Œæ¯ä¸ªé•¿å®½æ¯” arï¼š
            w = s * sqrt(ar)
            h = s / sqrt(ar)
        å…ˆæŒ‰ `cx,cy,w,h = (0,0,w,h)` æ„é€ ï¼Œå†è½¬æ¢ä¸º `xyxy`ã€‚

        è¿”å›
        ----------
        List[Tensor]ï¼š
            é•¿åº¦ = len(sizes)ï¼Œç¬¬ i é¡¹å½¢çŠ¶ä¸º [A, 4]ï¼ŒA=len(aspect_ratios)ï¼Œåæ ‡ä¸º xyxyã€‚
        """
        cell_anchors: List[torch.Tensor] = []
        for s in self.sizes:
            # ar = w/hï¼Œå› æ­¤ w = s*sqrt(ar), h = s/sqrt(ar)
            w = torch.tensor([s * math.sqrt(ar) for ar in self.aspect_ratios], dtype=torch.float32)
            h = torch.tensor([s / math.sqrt(ar) for ar in self.aspect_ratios], dtype=torch.float32)

            # ä»¥ (cx, cy) = (0, 0) çš„â€œåŸç‚¹é”šæ¡†â€ï¼Œåç»­ä»…åšå¹³ç§»å³å¯é“ºåˆ°ç½‘æ ¼
            base_cx = torch.zeros_like(w)
            base_cy = torch.zeros_like(h)
            base_cxcywh = torch.stack([base_cx, base_cy, w, h], dim=1)  # [A, 4] (cx,cy,w,h)
            base_anchors = self.cxcywh_to_xyxy(base_cxcywh)             # [A, 4] (xyxy)
            cell_anchors.append(base_anchors)

        return cell_anchors

    def cxcywh_to_xyxy(self, boxes: torch.Tensor) -> torch.Tensor:
        """
        å°† (cx, cy, w, h) è½¬ä¸º (x1, y1, x2, y2)ã€‚

        å‚æ•°
        ----------
        boxes : Tensor
            å½¢çŠ¶ [N, 4]ï¼Œå•ä½åƒç´ ã€‚

        è¿”å›
        ----------
        Tensor
            å½¢çŠ¶ [N, 4]ï¼Œ(x1, y1, x2, y2)ã€‚
        """
        return torch.cat([boxes[:, :2] - boxes[:, 2:] / 2,
                          boxes[:, :2] + boxes[:, 2:] / 2], dim=1)

    def xyxy_to_cxcywh(self, boxes: torch.Tensor) -> torch.Tensor:
        """
        å°† (x1, y1, x2, y2) è½¬ä¸º (cx, cy, w, h)ã€‚

        å‚æ•°
        ----------
        boxes : Tensor
            å½¢çŠ¶ [N, 4]ï¼Œå•ä½åƒç´ ã€‚

        è¿”å›
        ----------
        Tensor
            å½¢çŠ¶ [N, 4]ï¼Œ(cx, cy, w, h)ã€‚
        """
        w = boxes[:, 2] - boxes[:, 0]
        h = boxes[:, 3] - boxes[:, 1]
        cx = boxes[:, 0] + w / 2
        cy = boxes[:, 1] + h / 2
        return torch.stack([cx, cy, w, h], dim=1)

    def generate_anchors_on_grid(self, feature_maps: List[torch.Tensor], device: Union[str, torch.device]) -> torch.Tensor:
        """
        å°†æ¯å±‚çš„åŸºç¡€é”šæ¡†å¹³ç§»åˆ°å¯¹åº”ç‰¹å¾å›¾çš„æ¯ä¸ªç½‘æ ¼ä½ç½®ï¼Œå¾—åˆ°æ•´å¼ å›¾åƒçš„é”šæ¡†é›†åˆï¼ˆxyxyï¼‰ã€‚

        å‚æ•°
        ----------
        feature_maps : List[Tensor]
            FPN å„å±‚çš„ç‰¹å¾å›¾å¼ é‡åˆ—è¡¨ã€‚ä»…ä½¿ç”¨å…¶ç©ºé—´å°ºå¯¸ `H, W`ï¼›
            å½¢çŠ¶ä¸€èˆ¬ä¸º [N, C, H, W]ï¼ˆN å’Œ C ä¸å½±å“é”šæ¡†ç”Ÿæˆï¼‰ã€‚
        device : str | torch.device
            ç”Ÿæˆé”šæ¡†æ‰€åœ¨è®¾å¤‡ï¼ˆä¾‹å¦‚ "cpu" æˆ– "cuda"ï¼‰ï¼Œå°†ä¸ `cell_anchors` åšä¸€è‡´åŒ–ã€‚

        è¿”å›
        ----------
        Tensor
            æ‹¼æ¥åçš„æ‰€æœ‰å±‚é”šæ¡†ï¼Œå½¢çŠ¶ `[sum_i(H_i*W_i)*A, 4]`ï¼Œåæ ‡ä¸º xyxyã€‚

        ç»†èŠ‚è¯´æ˜
        ----------
        - å½“å‰å®ç°å‡è®¾è¾“å…¥å›¾åƒå¤§å°ä¸º **320x320**ï¼Œå¹¶æ®æ­¤ä»ç‰¹å¾å›¾å°ºå¯¸åæ¨å‡º strideï¼š
              stride_w = 320 / W_i, stride_h = 320 / H_i
          å¦‚æœä½ çš„å›¾åƒå°ºå¯¸å¹¶éå›ºå®š 320x320ï¼Œè¯·å°†ä¸‹æ–¹çš„ `input_size_h, input_size_w` æ”¹ä¸ºåŠ¨æ€å€¼ã€‚
        - `torch.meshgrid(..., indexing='ij')` ä¿è¯ `shift_y` å¯¹åº”ç¬¬ 0 ç»´ (è¡Œ/é«˜åº¦)ï¼Œ`shift_x` å¯¹åº”ç¬¬ 1 ç»´ (åˆ—/å®½åº¦)ã€‚
        - `shifts` çš„æ¯ä¸€è¡Œæ˜¯ `(x, y, x, y)`ï¼Œç”¨äºæŠŠâ€œä»¥åŸç‚¹ä¸ºä¸­å¿ƒâ€çš„ `cell_anchors` æ•´ä½“å¹³ç§»åˆ°ç½‘æ ¼ç‚¹å¤„ã€‚
        """
        all_anchors = []
        # âš ï¸ å‡è®¾è¾“å…¥ 320x320ï¼›è‹¥å¯å˜å°ºå¯¸ï¼Œè¯·æ”¹ä¸ºåŠ¨æ€å‚æ•°æˆ–ä»è°ƒç”¨æ–¹ä¼ å…¥
        input_size_h, input_size_w = 320, 320

        for i, fm in enumerate(feature_maps):
            fm_h, fm_w = fm.shape[-2], fm.shape[-1]
            stride_h = input_size_h / fm_h
            stride_w = input_size_w / fm_w

            # ç½‘æ ¼ä½ç§»ï¼šæ¯ä¸ªç½‘æ ¼ä¸­å¿ƒçš„ (x, y)ï¼ˆè¿™é‡Œç”¨å·¦ä¸Šå¯¹é½çš„æ•´æ•°æ­¥é•¿ä½ç½®ï¼›æ˜¯å¦åŠ 0.5ç”±æ£€æµ‹å¤´å¯¹é½ç­–ç•¥å†³å®šï¼‰
            shifts_x = torch.arange(0, fm_w, device=device, dtype=torch.float32) * stride_w
            shifts_y = torch.arange(0, fm_h, device=device, dtype=torch.float32) * stride_h
            shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x, indexing='ij')  # [H, W]

            # æ¯ä¸ªç½‘æ ¼ä½ç½®çš„å¹³ç§»é‡ (x, y, x, y)ï¼›ä¸ cell_anchors ç›¸åŠ å®Œæˆå¹³ç§»
            shifts = torch.stack(
                (shift_x.flatten(), shift_y.flatten(), shift_x.flatten(), shift_y.flatten()),
                dim=1
            )  # [H*W, 4]

            # å°†â€œåŸç‚¹é”šæ¡†â€å¹³ç§»åˆ°æ¯ä¸ªç½‘æ ¼ä½ç½®ï¼›å†å±•å¹³
            anchors = (self.cell_anchors[i].to(device).view(1, -1, 4) + shifts.view(-1, 1, 4)).reshape(-1, 4)
            all_anchors.append(anchors)

        return torch.cat(all_anchors, dim=0)


# =========================
# é¢å¤–å»ºè®®ï¼ˆå¯é€‰ï¼Œéå¿…é¡»æ”¹åŠ¨ï¼‰
# =========================
# 1) è‹¥è¾“å…¥å°ºå¯¸å¯å˜ï¼Œå¯æŠŠ generate_anchors_on_grid çš„ input_size ä½œä¸ºå‚æ•°ä¼ å…¥ï¼š
#    def generate_anchors_on_grid(self, feature_maps, device, input_size: Tuple[int, int]):
#        input_size_h, input_size_w = input_size
# 2) è‹¥ä½ çš„æ£€æµ‹å¤´å‡è®¾ç½‘æ ¼ä¸­å¿ƒåœ¨ (x+0.5, y+0.5)ï¼Œå¯ä»¥åœ¨ shifts_x / shifts_y ä¸ŠåŠ  0.5ï¼š
#        shifts_x = (torch.arange(...)+0.5) * stride_w
#        shifts_y = (torch.arange(...)+0.5) * stride_h
# 3) å½“å¸Œæœ›å¯¼å‡ºåˆ° ONNX/TS æ—¶ï¼Œæ³¨æ„é¿å…ä½¿ç”¨ Python float æ··å…¥ï¼ˆç¡®ä¿ dtype ä¸€è‡´ï¼‰ã€‚


# %% [markdown]
# ### ç¬¬ä¸‰æ­¥ï¼šå®Œæ•´çš„æŸå¤±å‡½æ•°ç±» `SSDLoss`
# 
# è¿™ä¸ªç±»å°†åŒ…å«ç›®æ ‡åˆ†é…å’ŒæŸå¤±è®¡ç®—çš„æ‰€æœ‰é€»è¾‘ã€‚

# %%
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision.ops import box_iou, sigmoid_focal_loss
from typing import List
class SSDLoss(nn.Module):
    """
    SSD/RetinaNet é£æ ¼çš„æ£€æµ‹æŸå¤±æ¨¡å—ï¼ˆåˆ†ç±» + è¾¹æ¡†å›å½’ï¼‰ã€‚

    æœ¬æ¨¡å—ä»¥**é¢„å…ˆç»™å®šçš„é”šæ¡† anchors**ä¸ºåŸºå‡†ï¼Œå°†æ¯ä¸ª batch çš„ GT æ ‡æ³¨åˆ†é…åˆ°é”šæ¡†ä¸Šï¼Œ
    ç„¶ååˆ†åˆ«è®¡ç®—ï¼š
      1) åˆ†ç±»æŸå¤±ï¼šä½¿ç”¨ `sigmoid_focal_loss`ï¼ˆå¤šæ ‡ç­¾å¼ï¼ŒæŒ‰ç±»åˆ«ç‹¬ç«‹äºŒåˆ†ç±»ï¼‰
      2) å›å½’æŸå¤±ï¼šå¯¹æ­£æ ·æœ¬ä½¿ç”¨ Smooth L1 (Huber) æŸå¤±ï¼Œå›å½’ (tx, ty, tw, th) å˜æ¢é‡

    ä¸»è¦æµç¨‹
    ----------
    1. `assign_targets_to_anchors`ï¼š
       - åŸºäº IoU å°† GT ä¸ anchors åŒ¹é…ï¼Œå¾—åˆ°æ¯ä¸ª anchor çš„ç±»åˆ«æ ‡ç­¾ä¸åŒ¹é…çš„ GT æ¡†ã€‚
       - é‡‡ç”¨â€œä¸ºæ¯ä¸ª GT è‡³å°‘åˆ†é…ä¸€ä¸ª anchorâ€çš„ç­–ç•¥ï¼šå¯¹æ¯ä¸ª GTï¼Œé€‰å– IoU æœ€é«˜çš„ anchor å¼ºåˆ¶æ­£æ ·æœ¬ã€‚
       - å…¶ä»– anchors ä¸­ï¼ŒIoU >= `iou_threshold_pos` è§†ä¸ºæ­£ï¼›å…¶ä½™ä¿æŒä¸ºâ€œèƒŒæ™¯/å¿½ç•¥â€ã€‚
         ï¼ˆæ­¤å®ç°æœªæ˜¾å¼å¤„ç† [neg, pos) çš„â€œå¿½ç•¥åŒºé—´â€ï¼Œè¯¦è§ä¸‹æ–¹æ³¨æ„äº‹é¡¹ï¼‰

    2. `encode_bbox`ï¼š
       - å°†åŒ¹é…çš„ GT æ¡†ä¸å¯¹åº” anchor æ¡†éƒ½ä» xyxy è½¬ä¸º cxcywhï¼Œç„¶åç¼–ç ä¸ºå›å½’ç›®æ ‡ï¼š
            tx = (cx_gt - cx_a) / w_a
            ty = (cy_gt - cy_a) / h_a
            tw = log(w_gt / w_a)
            th = log(h_gt / h_a)

    3. `forward`ï¼š
       - å°† `assigned_labels` one-hot åˆ° C ç»´ï¼ˆä¸¢å¼ƒèƒŒæ™¯/å¿½ç•¥çš„ç¬¬ C+1 ç±»ï¼‰ï¼Œ
         ç”¨ `sigmoid_focal_loss` åšåˆ†ç±»æŸå¤±ï¼ˆåœ¨ BÃ—AÃ—C ä¸Šæ±‚å’Œå†å¹³å‡ï¼‰ã€‚
       - å¯¹æ­£æ ·æœ¬ä½ç½®è®¡ç®— Smooth L1 å›å½’æŸå¤±ï¼Œå¹¶ç”¨æ­£æ ·æœ¬æ•°è¿›è¡Œå½’ä¸€åŒ–ã€‚

    åæ ‡ä¸å½¢çŠ¶çº¦å®š
    ----------
    - æ¡†åæ ‡é‡‡ç”¨åƒç´ å°ºåº¦ï¼š
        - è¾“å…¥/è¾“å‡º anchors ä¸ GTï¼š`[x1, y1, x2, y2]` (xyxy)
        - å›å½’ç¼–ç ï¼š`[tx, ty, tw, th]`
    - è¾“å…¥å¼ é‡å½¢çŠ¶ï¼š
        - `anchors`:   [A, 4]ï¼ŒA=æ€»é”šæ¡†æ•°ï¼ˆæ‰€æœ‰å±‚å…¨éƒ¨æ‹¼æ¥ï¼‰
        - `cls_preds`: [B, A, C]ï¼ŒC=ç±»åˆ«æ•°ï¼ˆä¸åŒ…å«èƒŒæ™¯ï¼‰
        - `reg_preds`: [B, A, 4]
        - `targets`:   é•¿åº¦ä¸º B çš„ Listï¼›æ¯ä¸ªå…ƒç´ å½¢å¦‚ [N_i, 5]ï¼Œåˆ—ä¸º (cls, x1, y1, x2, y2)
    - è¾“å‡ºï¼š
        - `loss_cls`: æ ‡é‡åˆ†ç±»æŸå¤±ï¼ˆå¹³å‡ï¼‰
        - `loss_reg`: æ ‡é‡å›å½’æŸå¤±ï¼ˆæŒ‰æ­£æ ·æœ¬æ•°å½’ä¸€åŒ–ï¼‰

    å‚æ•°
    ----------
    num_classes : int
        å‰æ™¯ç±»åˆ«æ•°ï¼ˆä¸å«èƒŒæ™¯ï¼‰ã€‚
    iou_threshold_pos : float
        æ­£æ ·æœ¬é˜ˆå€¼ï¼›å½“æŸ anchor ä¸æŸ GT çš„ IoU >= è¯¥é˜ˆå€¼æ—¶ï¼Œå¯è¢«æ ‡ä¸ºæ­£æ ·æœ¬ã€‚
    iou_threshold_neg : float
        è´Ÿæ ·æœ¬é˜ˆå€¼ï¼ˆå½“å‰å®ç°æ²¡æœ‰æ˜¾å¼ä½¿ç”¨â€œå¿½ç•¥åŒºé—´â€çš„é€»è¾‘ï¼Œä»…ä¿ç•™ä½œå‚æ•°å ä½ï¼‰ã€‚

    æ³¨æ„äº‹é¡¹
    ----------
    - æœ¬å®ç°çš„åˆ†ç±»æŸå¤±å¯¹æ‰€æœ‰ anchors éƒ½å‚ä¸ï¼ˆåŒ…å«æœªåŒ¹é…åˆ° GT çš„ä¸ºâ€œèƒŒæ™¯â€ï¼‰ï¼Œ
      å…·ä½“è¡¨ç°ä¸ºï¼š`one_hot` åä»… C ä¸ªå‰æ™¯é€šé“å‚ä¸ focal lossï¼ŒæœªåŒ¹é…å¤„ç›¸å½“äºå…¨é›¶ç›®æ ‡ã€‚
    - ç»å…¸ SSD ä¼šä½¿ç”¨â€œå›°éš¾æ ·æœ¬æŒ–æ˜/è´Ÿæ ·æœ¬é‡‡æ · (OHEM æˆ– fixed ratio)â€ï¼Œ
      å½“å‰å®ç°æœªåŠ å…¥é‡‡æ ·æˆ– `iou_threshold_neg` çš„å¿½ç•¥åŒºé—´é€»è¾‘ï¼›
      å¦‚éœ€ä¸¥æ ¼å¤ç° SSDï¼Œå¯åœ¨ assign æˆ– loss è®¡ç®—å¤„å¢åŠ é‡‡æ ·/å¿½ç•¥æœºåˆ¶ã€‚
    - `AnchorGenerator` ä»…ç”¨äºåæ ‡å˜æ¢ï¼ˆç¼–ç /è§£ç ï¼‰ç­‰è¾…åŠ©ï¼›anchors ç”±å¤–éƒ¨é¢„è®¡ç®—å¹¶ä¼ å…¥ã€‚
    """

    def __init__(self,
                 num_classes: int,
                 iou_threshold_pos: float = 0.5,
                 iou_threshold_neg: float = 0.4):
        super().__init__()
        self.num_classes = num_classes
        self.iou_threshold_pos = iou_threshold_pos
        self.iou_threshold_neg = iou_threshold_neg

        # AnchorGenerator å®ä¾‹ä»ç„¶éœ€è¦ï¼Œç”¨äºåæ ‡å˜æ¢ç­‰è¾…åŠ©åŠŸèƒ½ï¼ˆanchors æœ¬èº«ç”±å¤–éƒ¨ä¼ å…¥ï¼‰
        self.anchor_generator = AnchorGenerator()

        # å›å½’ç›®æ ‡çš„æ ‡å‡†å·®ï¼Œç”¨äºå½’ä¸€åŒ–
        # æ³¨å†Œä¸º bufferï¼šéš .to(device) ä¸€èµ·ç§»åŠ¨ï¼Œéš state_dict ä¸€èµ·ä¿å­˜
        self.register_buffer(
            "bbox_std",
            torch.tensor([0.1, 0.1, 0.2, 0.2], dtype=torch.float32)   # å›ºå®šæˆ float32
        )

    def assign_targets_to_anchors(self, anchors: torch.Tensor, targets: List[torch.Tensor]):
        """
        å°† GT åˆ†é…åˆ° anchorsï¼Œå¾—åˆ°æ¯ä¸ª anchor çš„ç±»åˆ«æ ‡ç­¾ä¸å¯¹åº”çš„ GT æ¡†ï¼ˆxyxyï¼‰ã€‚

        åˆ†é…ç­–ç•¥
        ----------
        - ä¸ºç¡®ä¿æ¯ä¸ª GT è‡³å°‘æœ‰ä¸€ä¸ªæ­£æ ·æœ¬ï¼šå¯¹æ¯ä¸ª GTï¼Œæ‰¾åˆ°ä¸å…¶ IoU æœ€å¤§çš„ anchorï¼Œå¼ºåˆ¶æ ‡ä¸ºè¯¥ GT çš„ç±»åˆ«ã€‚
        - åŒæ—¶ï¼Œå¯¹æ‰€æœ‰ anchorsï¼Œè‹¥å…¶ä¸ä»»ä¸€ GT çš„æœ€å¤§ IoU >= `iou_threshold_pos`ï¼Œæ ‡è®°ä¸ºè¯¥ GT çš„ç±»åˆ«ã€‚
        - å…¶ä»– anchors çš„æ ‡ç­¾ä¿æŒä¸º `num_classes`ï¼ˆå¯è§†ä¸ºâ€œèƒŒæ™¯/å¿½ç•¥â€ï¼‰ã€‚
        - è¯¥å‡½æ•°**æœª**ä½¿ç”¨ `iou_threshold_neg` åˆ›å»ºå¿½ç•¥åŒºé—´ï¼›å¦‚éœ€å¿½ç•¥ï¼Œå¯åœ¨æ­¤åŸºç¡€ä¸Šæ‰©å±•ã€‚

        å‚æ•°
        ----------
        anchors : Tensor
            å½¢çŠ¶ [A, 4] çš„é”šæ¡†ï¼ˆxyxyï¼Œå·²åœ¨æ­£ç¡®è®¾å¤‡ä¸Šï¼‰ã€‚
        targets : List[Tensor]
            é•¿åº¦ä¸º B çš„åˆ—è¡¨ï¼›ç¬¬ i ä¸ªå…ƒç´ å½¢çŠ¶ [N_i, 5]ï¼Œåˆ—ä¸º (cls, x1, y1, x2, y2)ã€‚

        è¿”å›
        ----------
        labels : Tensor
            å½¢çŠ¶ [B, A]ï¼Œæ¯ä¸ª anchor çš„ç±»åˆ« idï¼ˆ0..C-1 ä¸ºå‰æ™¯ï¼›C è¡¨ç¤ºèƒŒæ™¯/æœªåˆ†é…ï¼‰ã€‚
        matched_gt_boxes : Tensor
            å½¢çŠ¶ [B, A, 4]ï¼Œä¸æ¯ä¸ª anchor åŒ¹é…çš„ GT æ¡†ï¼ˆè‹¥æœªåŒ¹é…åˆ™ä¸º 0ï¼‰ã€‚
        """
        batch_size = len(targets)
        num_anchors = anchors.shape[0]
        device = anchors.device

        # åˆå§‹åŒ–ï¼šæ ‡ç­¾ä¸º Cï¼ˆè¡¨ç¤ºèƒŒæ™¯/æœªåˆ†é…ï¼‰ï¼ŒGT æ¡†ä¸º 0
        labels = torch.full((batch_size, num_anchors), self.num_classes, dtype=torch.int64, device=device)
        matched_gt_boxes = torch.zeros((batch_size, num_anchors, 4), dtype=torch.float32, device=device)

        for i in range(batch_size):
            # å°†labelç”±floatæ”¹ä¸ºintï¼Œè€Œbboxç»§ç»­ä¿æŒ [x_min, y_min, x_max, y_max]
            gt_boxes = targets[i][:, 1:]                    # [N_i, 4]
            gt_labels = targets[i][:, 0].to(torch.int64)    # [N_i]

            # æ—  ground-truth, ä¿æŒèƒŒæ™¯
            if gt_boxes.shape[0] == 0:
                continue

            # IoU è®¡ç®—ï¼šè¡Œ=GTï¼Œåˆ—=Anchor => [N_i, A]
            iou = box_iou(gt_boxes, anchors)

            # --- æ ¸å¿ƒä¿®æ”¹ï¼šå¼•å…¥ Ignore Zone ---
            max_iou_per_anchor, max_iou_idx_per_anchor = iou.max(dim=0)

            # 1. è´Ÿæ ·æœ¬ï¼šIoU < 0.4 çš„ anchor ä¿æŒä¸ºèƒŒæ™¯ (å·²ç»æ˜¯é»˜è®¤å€¼ self.num_classes)
            # neg_mask = max_iou_per_anchor < self.iou_threshold_neg (æ— éœ€æ“ä½œ)

            # 2. ç°åŒº/å¿½ç•¥æ ·æœ¬ï¼š0.4 <= IoU < 0.5 çš„ anchor æ ‡è®°ä¸º -1
            ignore_mask = (max_iou_per_anchor >= self.iou_threshold_neg) & (max_iou_per_anchor < self.iou_threshold_pos)
            labels[i, ignore_mask] = -1

            # 3. æ­£æ ·æœ¬ï¼šIoU >= 0.5 çš„ anchor
            # 2) å¯¹æ‰€æœ‰ anchor æ‰¾å…¶æœ€åŒ¹é…çš„ GTï¼Œå¹¶æŒ‰é˜ˆå€¼æ ‡ä¸ºæ­£æ ·æœ¬
            pos_mask = max_iou_per_anchor >= self.iou_threshold_pos
            if pos_mask.any():
                labels[i, pos_mask] = gt_labels[max_iou_idx_per_anchor[pos_mask]]
                matched_gt_boxes[i, pos_mask] = gt_boxes[max_iou_idx_per_anchor[pos_mask]]

            # 4. ç¡®ä¿æ¯ä¸ª GT è‡³å°‘æœ‰ä¸€ä¸ª anchor åŒ¹é… (æœ€é«˜ IoU åŒ¹é…)
            max_iou_per_gt, max_iou_idx_per_gt = iou.max(dim=1)
            labels[i, max_iou_idx_per_gt] = gt_labels
            matched_gt_boxes[i, max_iou_idx_per_gt] = gt_boxes

        return labels, matched_gt_boxes

    def encode_bbox(self, anchors: torch.Tensor, gt_boxes: torch.Tensor):
        """
        å°† GT æ¡†ç›¸å¯¹ anchor æ¡†ç¼–ç ä¸º (tx, ty, tw, th)ã€‚

        å‚æ•°
        ----------
        anchors : Tensor
            å½¢çŠ¶ [N, 4]ï¼Œanchor æ¡†ï¼ˆxyxyï¼‰ã€‚
        gt_boxes : Tensor
            å½¢çŠ¶ [N, 4]ï¼Œä¸ anchors ä¸€ä¸€å¯¹åº”çš„ GT æ¡†ï¼ˆxyxyï¼‰ã€‚

        è¿”å›
        ----------
        Tensor
            å½¢çŠ¶ [N, 4]ï¼Œåˆ—ä¸º (tx, ty, tw, th)ã€‚
        """

        anchors_c = self.anchor_generator.xyxy_to_cxcywh(anchors)
        gt_c      = self.anchor_generator.xyxy_to_cxcywh(gt_boxes)

        # ä½ç½®
        tx = (gt_c[:, 0] - anchors_c[:, 0]) / anchors_c[:, 2]
        ty = (gt_c[:, 1] - anchors_c[:, 1]) / anchors_c[:, 3]

        # å°ºå¯¸ï¼ˆå…³é”®ï¼šclamp é˜²æ­¢ log(0) / log(è´Ÿ)ï¼‰
        eps = 1e-6
        tw = torch.log((gt_c[:, 2] / anchors_c[:, 2]).clamp(min=eps))
        th = torch.log((gt_c[:, 3] / anchors_c[:, 3]).clamp(min=eps))

        # ç›´æ¥ç”¨ bufferï¼›ä¸ºé˜²æ­¢æ··åˆç²¾åº¦/è‡ªå®šä¹‰ dtypeï¼ŒåŒ¹é…åˆ°å½“å‰å¼ é‡ dtype
        device = anchors.device
        std = self.bbox_std.to(device=device, dtype=anchors.dtype) # æ˜¾å¼çš„å°†stdç§»åŠ¨åˆ°å¯¹åº”çš„è®¾å¤‡ä¸ŠCPU or CUDA

        # ä¿é™©ï¼šé™åˆ¶æç«¯æ®‹å·®ï¼Œé¿å…å•æ‰¹â€œå¼‚å¸¸å¤§æ¢¯åº¦â€
        deltas = torch.stack([tx, ty, tw, th], dim=1) / std
        deltas = deltas.clamp(min=-4.0, max=4.0)
        return deltas

    def forward(self, anchors: torch.Tensor, cls_preds: torch.Tensor, reg_preds: torch.Tensor, targets: List[torch.Tensor]):
        """
        è®¡ç®—æ€»æŸå¤±ï¼ˆåˆ†ç±» + å›å½’ï¼‰ã€‚

        å‚æ•°
        ----------
        anchors : Tensor
            [A, 4]ï¼Œæ‰€æœ‰å±‚çº§æ‹¼æ¥åçš„é”šæ¡†ï¼ˆxyxyï¼‰ï¼Œéœ€ä¸ `cls_preds`/`reg_preds` çš„ A å¯¹é½ã€‚
        cls_preds : Tensor
            [B, A, C]ï¼Œåˆ†ç±»é¢„æµ‹ï¼ˆæ¯ç±»ä¸€ä¸ªç‹¬ç«‹ sigmoidï¼‰ã€‚
        reg_preds : Tensor
            [B, A, 4]ï¼Œå›å½’é¢„æµ‹ï¼ˆä¸ anchors å¯¹é½ï¼Œå›å½’ (tx, ty, tw, th)ï¼‰ã€‚
        targets : List[Tensor]
            é•¿åº¦ä¸º B çš„åˆ—è¡¨ï¼›æ¯ä¸ªå…ƒç´  [N_i, 5]ï¼Œåˆ—ä¸º (cls, x1, y1, x2, y2)ã€‚

        è¿”å›
        ----------
        loss_cls : Tensor
            æ ‡é‡åˆ†ç±»æŸå¤±ã€‚
        loss_reg : Tensor
            æ ‡é‡å›å½’æŸå¤±ï¼ˆå¯¹æ­£æ ·æœ¬å¹³å‡ï¼›è‹¥æ— æ­£æ ·æœ¬åˆ™ä¸º 0ï¼‰ã€‚
        """
        device = cls_preds.device
        # 2. ç›®æ ‡åˆ†é… (ä½¿ç”¨ä¼ å…¥çš„ anchors)
        assigned_labels, assigned_gt_boxes = self.assign_targets_to_anchors(anchors.to(device), targets)

        # --- åˆ†ç±»æŸå¤±è®¡ç®— (å¤„ç† ignore) ---
        valid_mask = assigned_labels != -1  # è¿‡æ»¤æ‰ ignore=-1 çš„ anchor
        if not valid_mask.any():
             return torch.tensor(0.0, device=device), torch.tensor(0.0, device=device)

        # å‡†å¤‡ one-hot ç›®æ ‡ (å¯¹ valid anchor)
        labels_for_onehot = assigned_labels[valid_mask].clamp(min=0) # å°†èƒŒæ™¯(num_classes)ä¹Ÿè½¬ä¸º one-hot
        target_one_hot = F.one_hot(labels_for_onehot, num_classes=self.num_classes + 1)
        target_one_hot = target_one_hot[..., :self.num_classes].float()

        # è®¡ç®— focal loss (åªåœ¨ valid anchorä¸Š)
        loss_cls = sigmoid_focal_loss(
            cls_preds[valid_mask], target_one_hot,
            alpha=0.25, gamma=2.0, reduction='mean'
        )

        # --- å›å½’æŸå¤±è®¡ç®— (åªå¤„ç†æ­£æ ·æœ¬) ---
        pos_mask = (assigned_labels >= 0) & (assigned_labels < self.num_classes)
        num_pos = pos_mask.sum().item()
        if num_pos > 0:
            # å–å‡ºæ­£æ ·æœ¬ä½ç½®çš„å›å½’é¢„æµ‹ä¸åŒ¹é… GT
            pos_reg_preds = reg_preds[pos_mask]                 # [N_pos, 4]
            pos_gt_boxes = assigned_gt_boxes[pos_mask]          # [N_pos, 4]
            # å¯¹é½å¾—åˆ°ä¸æ­£æ ·æœ¬ç›¸åŒç´¢å¼•çš„ anchors
            pos_anchors = anchors.to(device).unsqueeze(0).expand_as(assigned_gt_boxes)[pos_mask]

            # è®¡ç®—å›å½’ç›®æ ‡å¹¶æ±‚ Smooth L1
            target_deltas = self.encode_bbox(pos_anchors, pos_gt_boxes)  # [N_pos, 4]

            # æ£€æµ‹é‡Œå¸¸ç”¨ beta=1/9ï¼ˆFaster/Mask R-CNN åŒæ¬¾ï¼‰ï¼Œèƒ½æ›´å¿«è¿›å…¥äºŒæ¬¡åŒºï¼Œè¿›ä¸€æ­¥æŠ‘åˆ¶å¤§æ®‹å·®çš„çº¿æ€§çˆ†å‘ï¼š
            # loss_reg = F.smooth_l1_loss(pos_reg_preds, target_deltas, beta=1.0, reduction='sum')  # åŸæœ¬çš„æ–¹å¼
            loss_reg = F.smooth_l1_loss(pos_reg_preds, target_deltas, beta=1/9, reduction='sum') / num_pos

            # æŒ‰æ­£æ ·æœ¬æ•°å½’ä¸€åŒ–
            loss_reg = loss_reg / num_pos
        else:
            loss_reg = torch.tensor(0.0, device=device)

        return loss_cls, loss_reg

# %% [markdown]
# ### è¯„ä¼°å‡½æ•°

# %%
from tqdm import tqdm

@torch.no_grad()
def evaluate(model, dataloader, criterion, anchor_generator, precomputed_anchors, device):
    """
    åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹ï¼Œè¿”å› (å¹³å‡æ€»æŸå¤±, å¹³å‡åˆ†ç±»æŸå¤±, å¹³å‡å›å½’æŸå¤±)ã€‚

    è¾“å…¥
    ----
    model : nn.Module
        å‰å‘è¿”å› (cls_preds, reg_preds) çš„æ£€æµ‹æ¨¡å‹ï¼š
        - cls_preds: [B, A, C]  (æœª sigmoid)
        - reg_preds: [B, A, 4]
    dataloader : torch.utils.data.DataLoader
        è¿­ä»£è¿”å› (imgs, targets, paths)ï¼š
        - imgs    : [B, 3, H, W]ï¼Œå·²å½’ä¸€åŒ–åˆ°ä¸è®­ç»ƒä¸€è‡´
        - targets : List[Tensor]ï¼Œé•¿åº¦ Bï¼›æ¯é¡¹ [N_i, 5]=[cls, x1, y1, x2, y2]
    criterion : nn.Module
        æŸå¤±è®¡ç®—å™¨ï¼ˆå¦‚ä½ ä¸Šé¢çš„ SSDLossï¼‰ï¼Œè°ƒç”¨æ–¹å¼ï¼š
        loss_cls, loss_reg = criterion(anchors, cls_preds, reg_preds, targets)
    anchor_generator : AnchorGenerator
        ä»…ä¸ºæ¥å£ç»Ÿä¸€ï¼Œå®é™…è¿™é‡Œä¸ç›´æ¥ç”¨ï¼ˆç”± criterion ä½¿ç”¨ï¼‰ã€‚
    precomputed_anchors : Tensor
        é¢„å…ˆç”Ÿæˆå¥½çš„æ‰€æœ‰ anchorsï¼Œå½¢çŠ¶ [A, 4]ï¼ˆä¸æ¨¡å‹è¾“å‡ºå¯¹é½ï¼‰ã€‚
    device : str | torch.device
        æ¨ç†è®¾å¤‡ã€‚

    å¤‡æ³¨
    ----
    - å†…éƒ¨ä¼šå°† model ç½®ä¸º eval æ¨¡å¼ï¼Œå¹¶åœ¨å‡½æ•°ç»“æŸåæ¢å¤ train æ¨¡å¼ï¼›
    - è®¡ç®—çš„æ˜¯ç®€å•çš„ batch å¹³å‡å†å¯¹ dataloader å–å¹³å‡ï¼ˆæ²¡æœ‰æŒ‰æ ·æœ¬æ•°åŠ æƒï¼‰ã€‚
    """
    model.eval()

    total_loss_cls = 0.0
    total_loss_reg = 0.0

    pbar = tqdm(dataloader, desc="  ğŸŸ¡ [Validating] ")
    for imgs, targets, _ in pbar:
        imgs = imgs.to(device)
        targets_on_device = [t.to(device) for t in targets]

        # å‰å‘ï¼šè¦æ±‚æ¨¡å‹è¿”å› (cls_preds, reg_preds)
        cls_preds, reg_preds = model(imgs)

        # è®¡ç®—æŸå¤±ï¼ˆanchors ç›´æ¥ä¼ å…¥ criterionï¼‰
        loss_cls, loss_reg = criterion(precomputed_anchors, cls_preds, reg_preds, targets_on_device)

        total_loss_cls += loss_cls.item()
        total_loss_reg += loss_reg.item()

        pbar.set_postfix(cls=f"{total_loss_cls:.6f}", reg=f"{total_loss_reg:.6f}")

    avg_cls_loss = total_loss_cls / len(dataloader)
    avg_reg_loss = total_loss_reg / len(dataloader)
    avg_total_loss = avg_cls_loss + avg_reg_loss

    model.train()  # æ¢å¤è®­ç»ƒæ¨¡å¼
    return avg_total_loss, avg_cls_loss, avg_reg_loss
